{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Diving into pygeoapi workshop! Version: 1.0 pygeoapi is a Python server implementation of the OGC API suite of standards. The project emerged as part of the next generation OGC API efforts in 2018 and provides the capability for organizations to deploy a RESTful OGC API endpoint using OpenAPI, GeoJSON, and HTML. pygeoapi is open source and released under an MIT license. Diving into pygeoapi is a half day workshop designed for users to become familiar with installing, configuring, publishing data to and extending pygeoapi. This workshop will cover publishing geospatial data to the Web using pygeoapi in support of the suite of OGC API standards. This workshop covers a wide range of topics (install/setup/configuration, publishing, cloud, templating, plugins, etc.). Please see the left hand navigation for the table of contents. Your FOSS4G 2022 workshop team Tom Kralidis Just van den Broecke Paul van Genuchten Joana Simoes Francesco Bartoli Angelos Tzotsos Antonio Cerciello About this tutorial This tutorial is a combination of step-by-step explanations of various aspects of pygeoapi as well as a series of exercises to familiarize yourself with the project. Exercises are indicated as follows: Example exercise A section marked like this indicates that you can try out the exercise. Also you will notice tips and notes setions within the text: Tip Tips share additional help on how to best achieve tasks Examples are indicated as follows: Code 1 2 3 4 5 < html > < head > < title > This is an HTML sample </ title > </ head > </ html > Configuration 1 2 3 4 my-collection : type : collection title : my cool collection title description : my cool collection description Snippets which need to be typed in a on a terminal/console are indicated as: echo 'Hello world' Workshop location and materials This workshop is always provided live at https://dive.pygeoapi.io . The workshop contents, wiki and issue tracker are managed on GitHub at https://github.com/geopython/diving-into-pygeoapi . Support A Gitter channel exists for discussion and live support from the developers of the workshop and other workshop participants. For issues/bugs/suggestions or improvements/contributions, use the GitHub issue tracker . All bugs, enhancements and issues can be reported on GitHub . As always, core pygeoapi support and community information can be found on the pygeoapi website . Contributions are always enncouraged and welcome! Now, on to the workshop. Let's go!","title":"Home"},{"location":"#welcome-to-the-diving-into-pygeoapi-workshop","text":"Version: 1.0 pygeoapi is a Python server implementation of the OGC API suite of standards. The project emerged as part of the next generation OGC API efforts in 2018 and provides the capability for organizations to deploy a RESTful OGC API endpoint using OpenAPI, GeoJSON, and HTML. pygeoapi is open source and released under an MIT license. Diving into pygeoapi is a half day workshop designed for users to become familiar with installing, configuring, publishing data to and extending pygeoapi. This workshop will cover publishing geospatial data to the Web using pygeoapi in support of the suite of OGC API standards. This workshop covers a wide range of topics (install/setup/configuration, publishing, cloud, templating, plugins, etc.). Please see the left hand navigation for the table of contents.","title":"Welcome to the Diving into pygeoapi workshop!"},{"location":"#your-foss4g-2022-workshop-team","text":"Tom Kralidis Just van den Broecke Paul van Genuchten Joana Simoes Francesco Bartoli Angelos Tzotsos Antonio Cerciello","title":"Your FOSS4G 2022 workshop team"},{"location":"#about-this-tutorial","text":"This tutorial is a combination of step-by-step explanations of various aspects of pygeoapi as well as a series of exercises to familiarize yourself with the project. Exercises are indicated as follows: Example exercise A section marked like this indicates that you can try out the exercise. Also you will notice tips and notes setions within the text: Tip Tips share additional help on how to best achieve tasks Examples are indicated as follows: Code 1 2 3 4 5 < html > < head > < title > This is an HTML sample </ title > </ head > </ html > Configuration 1 2 3 4 my-collection : type : collection title : my cool collection title description : my cool collection description Snippets which need to be typed in a on a terminal/console are indicated as: echo 'Hello world'","title":"About this tutorial"},{"location":"#workshop-location-and-materials","text":"This workshop is always provided live at https://dive.pygeoapi.io . The workshop contents, wiki and issue tracker are managed on GitHub at https://github.com/geopython/diving-into-pygeoapi .","title":"Workshop location and materials"},{"location":"#support","text":"A Gitter channel exists for discussion and live support from the developers of the workshop and other workshop participants. For issues/bugs/suggestions or improvements/contributions, use the GitHub issue tracker . All bugs, enhancements and issues can be reported on GitHub . As always, core pygeoapi support and community information can be found on the pygeoapi website . Contributions are always enncouraged and welcome!","title":"Support"},{"location":"#now-on-to-the-workshop-lets-go","text":"","title":"Now, on to the workshop.  Let's go!"},{"location":"conclusion/","text":"Conclusion We hope this workshop provided a valuable overview of the many features of pygeoapi. The project's goal is enabling low barrier, simple and flexible data publishing, using the OGC API suite of standards. FOSS4G 2022 For those in attendance at FOSS4G 2022 : come up and pick up your free pygeoapi t-shirt at the end of this workshop! the pygeoapi team will be at the community sprint on 27-28 August. Come join us! Contributing Suggestions, improvements and fixes are always welcome. Please visit our community page for more information on getting in touch. Thank you for your interest in pygeoapi!","title":"Conclusion"},{"location":"conclusion/#conclusion","text":"We hope this workshop provided a valuable overview of the many features of pygeoapi. The project's goal is enabling low barrier, simple and flexible data publishing, using the OGC API suite of standards.","title":"Conclusion"},{"location":"conclusion/#foss4g-2022","text":"For those in attendance at FOSS4G 2022 : come up and pick up your free pygeoapi t-shirt at the end of this workshop! the pygeoapi team will be at the community sprint on 27-28 August. Come join us!","title":"FOSS4G 2022"},{"location":"conclusion/#contributing","text":"Suggestions, improvements and fixes are always welcome. Please visit our community page for more information on getting in touch. Thank you for your interest in pygeoapi!","title":"Contributing"},{"location":"introduction/","text":"Introduction to pygeoapi The development team of pygeoapi (yes, spelled in lowercase) is excited to welcome you in this workshop! In this half day workshop, we will give you an introduction to pygeoapi, how to publish data, and provide resources and tips for future reading and reference (i.e. where to go when you don't know!). Although pygeoapi is written in Python and can be customizable and extensible (plugins) for Python developers, Python skills are not required to install, setup and publish your geospatial data as part of this workshop. All you need for the workshop is your favorite text editor and Docker (we will more information in the setup section ). Background reading The pygeoapi website is the main entrypoint for both end-users and developers where you can find: all documentation and presentations our default introductory default/latest presentation our code on GitHub all Docker images available on Docker Hub Given pygeoapi implements a number of OGC API standards, you may also want to read about these on ogcapi.ogc.org . Existing Deployments A number of organizations have deployed pygeoapi to their operatios. To get a feel of how pygeoapi is used in practice, check our up to date live deployments page . By default, the pygeoapi public demo at demo.pygeoapi.io is always maintained and made available by the development team. Check out the main instance which always runs the latest GitHub version. Interested in the demo site setup itself? demo.pygeoapi.io is developed in a GitHub repository using a DevOps continuous deployment (CD) workflow. Even more recent GitOps deployments were developed for Geonovum and the European Commission Joint Research Center . The above examples may help as starting points for your own pygeoapi setup and deployment, so feel free to study and use them! History Starting in 2018, pygeoapi emerged as part of the initial efforts for the development of OGC API standards. OGC API code sprints were instrumental for agile development and pouring the foundation of the project. The core design principles of the project were and are modularity, extensibility, building by exception, building on a large ecosystem of Free Open Source and OSGeo components such as GDAL, rasterio, Shapely, Pandas, Elasticsearch, PostGIS and many others. The project was initiated by Tom Kralidis . Within weeks, several talented developers joined the project, which led to the formation of a core team and Project Steering Committee (PSC) . Contributions continued as well from additional developers and users who happily provided new functionality, bug fixes, and documentation updates. As a result, a healthy community quickly emerged with a common interest in open source, OGC API standards, low barrier, modular and extensible. The rest, as they say, is history. pygeoapi is an OSGeo Project and an OGC Reference Implementation.","title":"Introduction to pygeoapi"},{"location":"introduction/#introduction-to-pygeoapi","text":"The development team of pygeoapi (yes, spelled in lowercase) is excited to welcome you in this workshop! In this half day workshop, we will give you an introduction to pygeoapi, how to publish data, and provide resources and tips for future reading and reference (i.e. where to go when you don't know!). Although pygeoapi is written in Python and can be customizable and extensible (plugins) for Python developers, Python skills are not required to install, setup and publish your geospatial data as part of this workshop. All you need for the workshop is your favorite text editor and Docker (we will more information in the setup section ).","title":"Introduction to pygeoapi"},{"location":"introduction/#background-reading","text":"The pygeoapi website is the main entrypoint for both end-users and developers where you can find: all documentation and presentations our default introductory default/latest presentation our code on GitHub all Docker images available on Docker Hub Given pygeoapi implements a number of OGC API standards, you may also want to read about these on ogcapi.ogc.org .","title":"Background reading"},{"location":"introduction/#existing-deployments","text":"A number of organizations have deployed pygeoapi to their operatios. To get a feel of how pygeoapi is used in practice, check our up to date live deployments page . By default, the pygeoapi public demo at demo.pygeoapi.io is always maintained and made available by the development team. Check out the main instance which always runs the latest GitHub version. Interested in the demo site setup itself? demo.pygeoapi.io is developed in a GitHub repository using a DevOps continuous deployment (CD) workflow. Even more recent GitOps deployments were developed for Geonovum and the European Commission Joint Research Center . The above examples may help as starting points for your own pygeoapi setup and deployment, so feel free to study and use them!","title":"Existing Deployments"},{"location":"introduction/#history","text":"Starting in 2018, pygeoapi emerged as part of the initial efforts for the development of OGC API standards. OGC API code sprints were instrumental for agile development and pouring the foundation of the project. The core design principles of the project were and are modularity, extensibility, building by exception, building on a large ecosystem of Free Open Source and OSGeo components such as GDAL, rasterio, Shapely, Pandas, Elasticsearch, PostGIS and many others. The project was initiated by Tom Kralidis . Within weeks, several talented developers joined the project, which led to the formation of a core team and Project Steering Committee (PSC) . Contributions continued as well from additional developers and users who happily provided new functionality, bug fixes, and documentation updates. As a result, a healthy community quickly emerged with a common interest in open source, OGC API standards, low barrier, modular and extensible. The rest, as they say, is history. pygeoapi is an OSGeo Project and an OGC Reference Implementation.","title":"History"},{"location":"setup/","text":"Workshop environment setup In this workshop we use the following materials: Documentation - (like this page): access latest on dive.pygeoapi.io Exercises - download the latest zip file , unzip, find exercises in workshop/exercises 1 Docker - all examples/exercises are run in a Docker container in workshop/exercises Text editor Your text editor needs to be able to edit configuration files in plain text . Below are some choices for text editors (there may be others), along with what some of the pygeoapi developers prefer to use: Notepad or Notepad++ (Windows) Sublime Text (all): Angelos IntelliJ IDEA (all): Just Emacs (all): Just Visual Studio Code (all): Francesco, Angelos, Joana /usr/bin/vim (all): Tom, Angelos Having said this, please feel free to use what works for you :) YAML Most exercises will focus on editing the pygeoapi configuration , which is in the YAML format. If you are not familiar with YAML, it is worth reading through a tutorial to become aware of YAML syntax and indentation. The main requirement for the training is to install Docker and/with Docker Compose on your system. We strongly advise to install Docker before the workshop starts. Although several custom installation scenarios are possible (see the documentation for more information), these are not considered in this workshop given the ability to install a fully reproducible environment via Docker and Docker Compose. Workshop Exercises will also be based on Docker, hence a custom installation would at least be 'challenging'. The good news is that only a single installation (Docker) is needed! The Docker images used in this workshop contain the latest pygeoapi and all its dependencies and external services (e.g. PostGIS). About Docker Docker has been available for almost 10 years, and provided as a deployment option on numerous FOSS software and OSGeo projects. Given the current era of computing, chances are that you have heard of Docker and containerization . Or, perhaps are already familiar and hopefully using Docker already. If not, there is a wide array of introductory materials that can be found online ( example from IBM . FOSS4G software has benefitted greatly from Docker (consistent packaging, isolation, integration and upgrade patterns) in comparison to custom installations. Though today we mainly use Docker, the bigger picture is the use of Containers as a next step in virtualization. Containerization certainly deserves its own workshop, so for the purpose of this workshop we cover the basics of Docker and Docker Compose. Docker Compose is an addition to Docker to facilitate the orchestration (configuration) of one or more Docker 'Containers' (a Container is a running instance of a Docker image) using a configuration convention (the Docker Compose YAML file), usually named docker-compose.yml . Stepping up further are even more sophisticated Docker orchestrators like Rancher and Kubernetes , but for this workshop, Docker and Docker Compose are all we need. Installation Docker installation has greatly progressed over the years. This is the only part of the workshop which is dependent on the system/OS you are running (e.g. Windows, Mac or Linux). For each system the Docker website provides detailed installation instructions. Please follow these consistently. Docker compose variants Docker Compose in older (pre Compose v2) versions was a separate (Python) program to install, though it was usually present in Docker Desktop. The docker compose command in that case is docker-compose (hyphened). Since 2021, Docker Desktop includes Compose in the Docker CLI. The command is then docker compose (space). In our texts we will use docker-compose . Depending on your installation you may need to replace the hyphen ( - ) with a space. But you can always install the original compose ( docker-compose ) via pip install docker-compose . For many platforms a product called Docker Desktop is available, which includes Docker compose : Windows installation Mac installation Linux installation Some notes: On Windows we recommend using the Windows Subsystem for Linux (WSL) as it also provides a powerful (Bash) command line and has optimal integration with Docker On Mac, if you are using Homebrew , consider (as the author has) using the brew Docker formula On MacOS Monterey, there is an issue with the port 5000 that is already used and therefore conflicting to the default one used by pygeoapi. If you are facing with this error OSError: [Errno 48] Address already in use then your machine is affected. To overcome the issue you can disable the Airplay Receiver from System Preference->Sharing of your MacOS (detailed description in this blog post ). On Linux, you can choose the relevant installer for your platform. You can also use Virtualbox with a Ubuntu Image or use a cloud VM Docker desktop includes a graphical user interface with some interesting options. You can see logs and information about running containers, open their service in a browser or even open a terminal inside the container If all goes well, you should be able to run Docker from the command line as follows: 2 docker --version Docker version 20 .10.17, build 100c701 docker-compose --version Docker Compose version v2.6.1 Quickstart Once Docker is available on your system, running the pygeoapi container with its built-in configuration and data is a one-liner. First run via Docker Open a terminal session and run: docker run --rm -p 5000 :80 geopython/pygeoapi:latest Unable to find image 'geopython/pygeoapi:latest' locally latest: Pulling from geopython/pygeoapi d7bfe07ed847: Already exists d5d0144a7164: Already exists afe0923a0fa0: Already exists 75f8618c4e86: Already exists c603397fd6ad: Already exists 6584a95328b3: Already exists fd93e44631d9: Already exists 6a3201071a5d: Already exists 4f4fb700ef54: Already exists Digest: sha256:27b2b219497a6ea382a946ee90ae96ad00b5c1d8e9b725fccf23211978fef124 Status: Downloaded newer image for geopython/pygeoapi:latest START /entrypoint.sh Trying to generate openapi.yml openapi.yml generated continue to pygeoapi make SCRIPT_NAME empty from / Start gunicorn name = pygeoapi on 0 .0.0.0:80 with 4 workers and SCRIPT_NAME = [ 2022 -08-09 12 :59:00 +0000 ] [ 1 ] [ INFO ] Starting gunicorn 20 .0.4 [ 2022 -08-09 12 :59:00 +0000 ] [ 1 ] [ INFO ] Listening at: http://0.0.0.0:80 ( 1 ) [ 2022 -08-09 12 :59:00 +0000 ] [ 1 ] [ INFO ] Using worker: gevent [ 2022 -08-09 12 :59:00 +0000 ] [ 18 ] [ INFO ] Booting worker with pid: 18 [ 2022 -08-09 12 :59:00 +0000 ] [ 19 ] [ INFO ] Booting worker with pid: 19 [ 2022 -08-09 12 :59:00 +0000 ] [ 21 ] [ INFO ] Booting worker with pid: 21 [ 2022 -08-09 12 :59:00 +0000 ] [ 22 ] [ INFO ] Booting worker with pid: 22 That's all! Open your browser and navigate to http://localhost:5000 , the pygeoapi page will display. As part of the initial docker run , Docker will download the pygeoapi Docker Image from Docker hub . This may take some time, as the Docker image includes all dependencies (such as GDAL, etc.). Be patient! This is a one-time download for the entire workshop, or you may want to do this beforehand. Some notes: Docker runs a pygeoapi container on your local system on port 5000, which is mapped to port 80 inside the container the pygeoapi Docker container runs with the default configuration and data from the GitHub repo the --rm option removes the Docker Container (but not the image), after execution type CTRL-C to stop the container and return to the terminal Next, you can override the default configuration and add your own data using Docker volumes . Customizing configuration In the upcoming exercises we are going to update the configuration file multiple times. For ease of development we are overriding the pygeoapi configuration which resides by default at /pygeoapi/local.config.yml within the container by a local file which you can edit in your favourite text editor. Override the pygeoapi config file Download pygeoapi's default Docker configuration from default.config.yml to the current folder (or navigate to the folder where you downloaded the file), for example with: curl -O https://raw.githubusercontent.com/geopython/pygeoapi/master/Docker/default.config.yml Open the file in your favourite text editor and change the title and description of the API: 59 60 61 62 metadata: identification: title: My first pygeoapi run description: pygeoapi provides an API to geospatial data Now run the container with the overridden config file: docker run -p 5000 :80 \\ -v $( pwd ) /default.config.yml:/pygeoapi/local.config.yml \\ geopython/pygeoapi:latest At this point, navigate to http://localhost:5000 to verify the new title and description. By using a Docker volume mount ( -v option), Docker attaches or 'mounts' a directory or single file from your host/local system into the Docker Container. In the above snippet, $(pwd) indicates the working folder from which you start the Docker container. Adding data and setting the configuration file In addition to adapting the configuration you will usually add your own data as files or remote data services like PostGIS or WFS. You can also mount a local directory such as data/ to /pygeoapi/mydata within the Container. Within the data directory you can store vector data, raster files or sets of image of vector tiles. Below is an example where the configuration is explictly set to pygeoapi-config.yml via an environment variable ( -e ) and uses a Docker mount to mount the local data folder as /pygeoapi/mydata : docker run -p 5000 :80 \\ -v $( pwd ) /data:/pygeoapi/mydata \\ -v $( pwd ) /default.config.yml:/pygeoapi/pygeoapi-config.yml \\ -e PYGEOAPI_CONFIG = /pygeoapi/pygeoapi-config.yml \\ geopython/pygeoapi:latest In the next sections we will review additional examples of mounts to the data folder. More Docker deployment examples can be found in the pygeoapi GitHub repository . alternatively, you can fork/clone the GitHub repository of this workshop directly from https://github.com/geopython/diving-into-pygeoapi. \u21a9 For recent version of Docker run docker compose version \u21a9","title":"Workshop environment setup"},{"location":"setup/#workshop-environment-setup","text":"In this workshop we use the following materials: Documentation - (like this page): access latest on dive.pygeoapi.io Exercises - download the latest zip file , unzip, find exercises in workshop/exercises 1 Docker - all examples/exercises are run in a Docker container in workshop/exercises","title":"Workshop environment setup"},{"location":"setup/#text-editor","text":"Your text editor needs to be able to edit configuration files in plain text . Below are some choices for text editors (there may be others), along with what some of the pygeoapi developers prefer to use: Notepad or Notepad++ (Windows) Sublime Text (all): Angelos IntelliJ IDEA (all): Just Emacs (all): Just Visual Studio Code (all): Francesco, Angelos, Joana /usr/bin/vim (all): Tom, Angelos Having said this, please feel free to use what works for you :)","title":"Text editor"},{"location":"setup/#yaml","text":"Most exercises will focus on editing the pygeoapi configuration , which is in the YAML format. If you are not familiar with YAML, it is worth reading through a tutorial to become aware of YAML syntax and indentation. The main requirement for the training is to install Docker and/with Docker Compose on your system. We strongly advise to install Docker before the workshop starts. Although several custom installation scenarios are possible (see the documentation for more information), these are not considered in this workshop given the ability to install a fully reproducible environment via Docker and Docker Compose. Workshop Exercises will also be based on Docker, hence a custom installation would at least be 'challenging'. The good news is that only a single installation (Docker) is needed! The Docker images used in this workshop contain the latest pygeoapi and all its dependencies and external services (e.g. PostGIS).","title":"YAML"},{"location":"setup/#about-docker","text":"Docker has been available for almost 10 years, and provided as a deployment option on numerous FOSS software and OSGeo projects. Given the current era of computing, chances are that you have heard of Docker and containerization . Or, perhaps are already familiar and hopefully using Docker already. If not, there is a wide array of introductory materials that can be found online ( example from IBM . FOSS4G software has benefitted greatly from Docker (consistent packaging, isolation, integration and upgrade patterns) in comparison to custom installations. Though today we mainly use Docker, the bigger picture is the use of Containers as a next step in virtualization. Containerization certainly deserves its own workshop, so for the purpose of this workshop we cover the basics of Docker and Docker Compose. Docker Compose is an addition to Docker to facilitate the orchestration (configuration) of one or more Docker 'Containers' (a Container is a running instance of a Docker image) using a configuration convention (the Docker Compose YAML file), usually named docker-compose.yml . Stepping up further are even more sophisticated Docker orchestrators like Rancher and Kubernetes , but for this workshop, Docker and Docker Compose are all we need.","title":"About Docker"},{"location":"setup/#installation","text":"Docker installation has greatly progressed over the years. This is the only part of the workshop which is dependent on the system/OS you are running (e.g. Windows, Mac or Linux). For each system the Docker website provides detailed installation instructions. Please follow these consistently. Docker compose variants Docker Compose in older (pre Compose v2) versions was a separate (Python) program to install, though it was usually present in Docker Desktop. The docker compose command in that case is docker-compose (hyphened). Since 2021, Docker Desktop includes Compose in the Docker CLI. The command is then docker compose (space). In our texts we will use docker-compose . Depending on your installation you may need to replace the hyphen ( - ) with a space. But you can always install the original compose ( docker-compose ) via pip install docker-compose . For many platforms a product called Docker Desktop is available, which includes Docker compose : Windows installation Mac installation Linux installation Some notes: On Windows we recommend using the Windows Subsystem for Linux (WSL) as it also provides a powerful (Bash) command line and has optimal integration with Docker On Mac, if you are using Homebrew , consider (as the author has) using the brew Docker formula On MacOS Monterey, there is an issue with the port 5000 that is already used and therefore conflicting to the default one used by pygeoapi. If you are facing with this error OSError: [Errno 48] Address already in use then your machine is affected. To overcome the issue you can disable the Airplay Receiver from System Preference->Sharing of your MacOS (detailed description in this blog post ). On Linux, you can choose the relevant installer for your platform. You can also use Virtualbox with a Ubuntu Image or use a cloud VM Docker desktop includes a graphical user interface with some interesting options. You can see logs and information about running containers, open their service in a browser or even open a terminal inside the container If all goes well, you should be able to run Docker from the command line as follows: 2 docker --version Docker version 20 .10.17, build 100c701 docker-compose --version Docker Compose version v2.6.1","title":"Installation"},{"location":"setup/#quickstart","text":"Once Docker is available on your system, running the pygeoapi container with its built-in configuration and data is a one-liner. First run via Docker Open a terminal session and run: docker run --rm -p 5000 :80 geopython/pygeoapi:latest Unable to find image 'geopython/pygeoapi:latest' locally latest: Pulling from geopython/pygeoapi d7bfe07ed847: Already exists d5d0144a7164: Already exists afe0923a0fa0: Already exists 75f8618c4e86: Already exists c603397fd6ad: Already exists 6584a95328b3: Already exists fd93e44631d9: Already exists 6a3201071a5d: Already exists 4f4fb700ef54: Already exists Digest: sha256:27b2b219497a6ea382a946ee90ae96ad00b5c1d8e9b725fccf23211978fef124 Status: Downloaded newer image for geopython/pygeoapi:latest START /entrypoint.sh Trying to generate openapi.yml openapi.yml generated continue to pygeoapi make SCRIPT_NAME empty from / Start gunicorn name = pygeoapi on 0 .0.0.0:80 with 4 workers and SCRIPT_NAME = [ 2022 -08-09 12 :59:00 +0000 ] [ 1 ] [ INFO ] Starting gunicorn 20 .0.4 [ 2022 -08-09 12 :59:00 +0000 ] [ 1 ] [ INFO ] Listening at: http://0.0.0.0:80 ( 1 ) [ 2022 -08-09 12 :59:00 +0000 ] [ 1 ] [ INFO ] Using worker: gevent [ 2022 -08-09 12 :59:00 +0000 ] [ 18 ] [ INFO ] Booting worker with pid: 18 [ 2022 -08-09 12 :59:00 +0000 ] [ 19 ] [ INFO ] Booting worker with pid: 19 [ 2022 -08-09 12 :59:00 +0000 ] [ 21 ] [ INFO ] Booting worker with pid: 21 [ 2022 -08-09 12 :59:00 +0000 ] [ 22 ] [ INFO ] Booting worker with pid: 22 That's all! Open your browser and navigate to http://localhost:5000 , the pygeoapi page will display. As part of the initial docker run , Docker will download the pygeoapi Docker Image from Docker hub . This may take some time, as the Docker image includes all dependencies (such as GDAL, etc.). Be patient! This is a one-time download for the entire workshop, or you may want to do this beforehand. Some notes: Docker runs a pygeoapi container on your local system on port 5000, which is mapped to port 80 inside the container the pygeoapi Docker container runs with the default configuration and data from the GitHub repo the --rm option removes the Docker Container (but not the image), after execution type CTRL-C to stop the container and return to the terminal Next, you can override the default configuration and add your own data using Docker volumes .","title":"Quickstart"},{"location":"setup/#customizing-configuration","text":"In the upcoming exercises we are going to update the configuration file multiple times. For ease of development we are overriding the pygeoapi configuration which resides by default at /pygeoapi/local.config.yml within the container by a local file which you can edit in your favourite text editor. Override the pygeoapi config file Download pygeoapi's default Docker configuration from default.config.yml to the current folder (or navigate to the folder where you downloaded the file), for example with: curl -O https://raw.githubusercontent.com/geopython/pygeoapi/master/Docker/default.config.yml Open the file in your favourite text editor and change the title and description of the API: 59 60 61 62 metadata: identification: title: My first pygeoapi run description: pygeoapi provides an API to geospatial data Now run the container with the overridden config file: docker run -p 5000 :80 \\ -v $( pwd ) /default.config.yml:/pygeoapi/local.config.yml \\ geopython/pygeoapi:latest At this point, navigate to http://localhost:5000 to verify the new title and description. By using a Docker volume mount ( -v option), Docker attaches or 'mounts' a directory or single file from your host/local system into the Docker Container. In the above snippet, $(pwd) indicates the working folder from which you start the Docker container.","title":"Customizing configuration"},{"location":"setup/#adding-data-and-setting-the-configuration-file","text":"In addition to adapting the configuration you will usually add your own data as files or remote data services like PostGIS or WFS. You can also mount a local directory such as data/ to /pygeoapi/mydata within the Container. Within the data directory you can store vector data, raster files or sets of image of vector tiles. Below is an example where the configuration is explictly set to pygeoapi-config.yml via an environment variable ( -e ) and uses a Docker mount to mount the local data folder as /pygeoapi/mydata : docker run -p 5000 :80 \\ -v $( pwd ) /data:/pygeoapi/mydata \\ -v $( pwd ) /default.config.yml:/pygeoapi/pygeoapi-config.yml \\ -e PYGEOAPI_CONFIG = /pygeoapi/pygeoapi-config.yml \\ geopython/pygeoapi:latest In the next sections we will review additional examples of mounts to the data folder. More Docker deployment examples can be found in the pygeoapi GitHub repository . alternatively, you can fork/clone the GitHub repository of this workshop directly from https://github.com/geopython/diving-into-pygeoapi. \u21a9 For recent version of Docker run docker compose version \u21a9","title":"Adding data and setting the configuration file"},{"location":"standards/","text":"Overview This section provides a high level overview of pygeoapi standards support. Standards Open standards are core to pygeoapi. Open standards allow for broad interoperability and plug and play capability. pygeoapi supports a number of open standards (both formal and defacto or community driven). API standards OGC API pygeoapi implements the OGC API suite of standards from the Open Geospatial Consortium (OGC). From the OGC API website: Cite The OGC API family of standards are being developed to make it easy for anyone to provide geospatial data to the web. These standards build upon the legacy of the OGC Web Service standards (WMS, WFS, WCS, WPS, etc.), but define resource-centric APIs that take advantage of modern web development practices. This web page provides information on these standards in a consolidated location. These standards are being constructed as \"building blocks\" that can be used to assemble novel APIs for web access to geospatial content. The building blocks are defined not only by the requirements of the specific standards, but also through interoperability prototyping and testing in OGC's Innovation Program. OGC API - Common OGC API - Common is a common framework used in all OGC API's. OGC API - Common Common provides the following functionality: based on OpenAPI 3.0 HTML and JSON as the dominant encodings, alternative encodings are possible common and shared endpoints such as: / (landing page) /conformance /openapi /collections /collections/foo common aspects such as pagination, links between resources, basic filtering, query parameters ( bbox , datetime , etc.) OGC API - Common allows for specification developers to focus on the key functionality of a given API (i.e. data access, etc.) while using common constructs. This harmonizes OGC API standards and enables deeper integration with less code. This also allows for OGC API client software to be more streamlined. The /conformance endpoint indicates which standards and extensions are supported by a deployment of OGC API. OGC API building blocks The OGC API approach allows for modularity and \"profiling\" of APIs depending on your requirements. This means you can mix and match OGC APIs together. You can read more about this topic in the building blocks website . More OGC APIs The OGC API effort is rapidly evolving. Numerous OGC API standards are in development, and will be implemented in pygeoapi over time: Maps can serve spatially referenced and dynamically rendered map imagery Routes provides access to routing data Styles defines a Web API that enables map servers, clients as well as visual style editors, to manage and fetch styles 3D GeoVolumes facilitates efficient discovery of and access to 3D content in multiple formats based on a space-centric perspective Moving Features defines an API that provides access to data representing features that move as rigid bodies Joins supports the joining of data, from multiple sources, with feature collections or directly with other input files Discrete Global Grid System enables applications to organise and access data arranged according to a Discrete Global Grid System (DGGS) OGC APIs supported by pygeoapi pygeoapi is an OGC API Reference Implemetnation and implements numerous OGC API standards. Standard pygeoapi status Included in this workshop OGC API - Features Reference \u2705 OGC API - Coverages Implementing \u2705 OGC API - Tiles Implementing \u2705 OGC API - Processes Implementing \u2705 OGC API - Records Implementing \u2705 OGC API - Environmental Data Retrieval Implementing \u2705 OGC API - Routes Planned OGC API - Maps Planned OGC API - Styles Planned In the next section we will dive into the dedicated API's related to specific types of information. You will notice that all APIs are combined and available via a single OGC API endpoint, thanks to OGC API - Common. OpenAPI Core to OGC API - Common is the OpenAPI initiative to help describe and document an API. OpenAPI defines its structure in an OpenAPI document. OGC API - Common suggests this document to be located at /openapi . With pygeoapi in a browser this URL opens an interactive HTML page which facilitates an API query. Append ?f=json to view the document in JSON. The OpenAPI document indicates which endpoints are available in the service, which parameters it accepts and what types of responses can be expected. The OpenAPI document is a similar concept to Capabilities XML as part of the first genration OGC Web Service standards. OpenAPI Specification parsing in a browser A common approach to interact with Open API's using json is to use a program like Postman . Also there are browser plugins which enable to define api requests interactively within a browser. For firefox download the plugin poster . For Chrome and Edge use Boomerang . In Boomerang you can create individual web requests, but also load the open api specification document and interact with any of the advertised endpoints. The OpenAPI community provides various tools, such as a validator for OAS documents or generate code as a starting point for client development. Content and format standards JSON is core in pygeoapi, providing a format that is machine readable and easy to parse and handle by client software and tools. OGC API - Common provides uniform JSON formats for the various endpoints it supports. Specific OGC API standards may specify domain specific formats (for example, GeoJSON for OGC API - Features, GeoTIFF for OGC API - Coverages) depending on the data type(s). pygeoapi specific conventions pygeoapi provides some conventions that are not put forth by OGC API standards, however facilitate some features and capabiliteis. the f parameter The f parameter can be used with any pygeoapi endpoint to specify an output format for a given API request. Examples are f=html , f=json , etc. Using a web browser to access OGC API Use your web browser to navigate to demo.pygeoapi.io . A browser by default opens any OGC API in HTML (as a webpage) due to the accept header sent by the browser ( text/html ). On the right top corner you will notice a JSON link. The link adds the parameter to the url: f=json , which is a mechanism of pygeoapi to override the accept header sent by the web browser. Note When calling an OGC API from javascript, and the aim is to receive json. You can use the ?f=json pygeoapi convention, or the content negotiation as provided by the standard; include a header accept:\"application/json\" in your request. In jquery for example, this is represented by the dataType property 1 2 3 4 5 $ . ajax ({ method : \"GET\" , url : \"https://demo.pygeoapi.io/master\" , dataType : \"json\" }); the skipGeometry parameter The skipGeometry ( true|false , default is false ) parameter can be used with feature data access to facilitate downloading vector data without geometry if desired. Summary Standards are a cornerstone of pygeoapi, and will enable you to publish your data efficiently and with a low barrier for users. Now, let's get to the action: Publishing data !","title":"Standards"},{"location":"standards/#overview","text":"This section provides a high level overview of pygeoapi standards support.","title":"Overview"},{"location":"standards/#standards","text":"Open standards are core to pygeoapi. Open standards allow for broad interoperability and plug and play capability. pygeoapi supports a number of open standards (both formal and defacto or community driven).","title":"Standards"},{"location":"standards/#api-standards","text":"","title":"API standards"},{"location":"standards/#ogc-api","text":"pygeoapi implements the OGC API suite of standards from the Open Geospatial Consortium (OGC). From the OGC API website: Cite The OGC API family of standards are being developed to make it easy for anyone to provide geospatial data to the web. These standards build upon the legacy of the OGC Web Service standards (WMS, WFS, WCS, WPS, etc.), but define resource-centric APIs that take advantage of modern web development practices. This web page provides information on these standards in a consolidated location. These standards are being constructed as \"building blocks\" that can be used to assemble novel APIs for web access to geospatial content. The building blocks are defined not only by the requirements of the specific standards, but also through interoperability prototyping and testing in OGC's Innovation Program.","title":"OGC API"},{"location":"standards/#ogc-api-common","text":"OGC API - Common is a common framework used in all OGC API's. OGC API - Common Common provides the following functionality: based on OpenAPI 3.0 HTML and JSON as the dominant encodings, alternative encodings are possible common and shared endpoints such as: / (landing page) /conformance /openapi /collections /collections/foo common aspects such as pagination, links between resources, basic filtering, query parameters ( bbox , datetime , etc.) OGC API - Common allows for specification developers to focus on the key functionality of a given API (i.e. data access, etc.) while using common constructs. This harmonizes OGC API standards and enables deeper integration with less code. This also allows for OGC API client software to be more streamlined. The /conformance endpoint indicates which standards and extensions are supported by a deployment of OGC API.","title":"OGC API - Common"},{"location":"standards/#ogc-api-building-blocks","text":"The OGC API approach allows for modularity and \"profiling\" of APIs depending on your requirements. This means you can mix and match OGC APIs together. You can read more about this topic in the building blocks website .","title":"OGC API building blocks"},{"location":"standards/#more-ogc-apis","text":"The OGC API effort is rapidly evolving. Numerous OGC API standards are in development, and will be implemented in pygeoapi over time: Maps can serve spatially referenced and dynamically rendered map imagery Routes provides access to routing data Styles defines a Web API that enables map servers, clients as well as visual style editors, to manage and fetch styles 3D GeoVolumes facilitates efficient discovery of and access to 3D content in multiple formats based on a space-centric perspective Moving Features defines an API that provides access to data representing features that move as rigid bodies Joins supports the joining of data, from multiple sources, with feature collections or directly with other input files Discrete Global Grid System enables applications to organise and access data arranged according to a Discrete Global Grid System (DGGS)","title":"More OGC APIs"},{"location":"standards/#ogc-apis-supported-by-pygeoapi","text":"pygeoapi is an OGC API Reference Implemetnation and implements numerous OGC API standards. Standard pygeoapi status Included in this workshop OGC API - Features Reference \u2705 OGC API - Coverages Implementing \u2705 OGC API - Tiles Implementing \u2705 OGC API - Processes Implementing \u2705 OGC API - Records Implementing \u2705 OGC API - Environmental Data Retrieval Implementing \u2705 OGC API - Routes Planned OGC API - Maps Planned OGC API - Styles Planned In the next section we will dive into the dedicated API's related to specific types of information. You will notice that all APIs are combined and available via a single OGC API endpoint, thanks to OGC API - Common.","title":"OGC APIs supported by pygeoapi"},{"location":"standards/#openapi","text":"Core to OGC API - Common is the OpenAPI initiative to help describe and document an API. OpenAPI defines its structure in an OpenAPI document. OGC API - Common suggests this document to be located at /openapi . With pygeoapi in a browser this URL opens an interactive HTML page which facilitates an API query. Append ?f=json to view the document in JSON. The OpenAPI document indicates which endpoints are available in the service, which parameters it accepts and what types of responses can be expected. The OpenAPI document is a similar concept to Capabilities XML as part of the first genration OGC Web Service standards. OpenAPI Specification parsing in a browser A common approach to interact with Open API's using json is to use a program like Postman . Also there are browser plugins which enable to define api requests interactively within a browser. For firefox download the plugin poster . For Chrome and Edge use Boomerang . In Boomerang you can create individual web requests, but also load the open api specification document and interact with any of the advertised endpoints. The OpenAPI community provides various tools, such as a validator for OAS documents or generate code as a starting point for client development.","title":"OpenAPI"},{"location":"standards/#content-and-format-standards","text":"JSON is core in pygeoapi, providing a format that is machine readable and easy to parse and handle by client software and tools. OGC API - Common provides uniform JSON formats for the various endpoints it supports. Specific OGC API standards may specify domain specific formats (for example, GeoJSON for OGC API - Features, GeoTIFF for OGC API - Coverages) depending on the data type(s).","title":"Content and format standards"},{"location":"standards/#pygeoapi-specific-conventions","text":"pygeoapi provides some conventions that are not put forth by OGC API standards, however facilitate some features and capabiliteis.","title":"pygeoapi specific conventions"},{"location":"standards/#the-f-parameter","text":"The f parameter can be used with any pygeoapi endpoint to specify an output format for a given API request. Examples are f=html , f=json , etc. Using a web browser to access OGC API Use your web browser to navigate to demo.pygeoapi.io . A browser by default opens any OGC API in HTML (as a webpage) due to the accept header sent by the browser ( text/html ). On the right top corner you will notice a JSON link. The link adds the parameter to the url: f=json , which is a mechanism of pygeoapi to override the accept header sent by the web browser. Note When calling an OGC API from javascript, and the aim is to receive json. You can use the ?f=json pygeoapi convention, or the content negotiation as provided by the standard; include a header accept:\"application/json\" in your request. In jquery for example, this is represented by the dataType property 1 2 3 4 5 $ . ajax ({ method : \"GET\" , url : \"https://demo.pygeoapi.io/master\" , dataType : \"json\" });","title":"the f parameter"},{"location":"standards/#the-skipgeometry-parameter","text":"The skipGeometry ( true|false , default is false ) parameter can be used with feature data access to facilitate downloading vector data without geometry if desired.","title":"the skipGeometry parameter"},{"location":"standards/#summary","text":"Standards are a cornerstone of pygeoapi, and will enable you to publish your data efficiently and with a low barrier for users. Now, let's get to the action: Publishing data !","title":"Summary"},{"location":"advanced/","text":"Advanced topics In this section, we will discuss more advanced pygeoapi topics primarily focused on extending pygeoapi via custom development and deployment. Multilingual support UI customization and templating Using pygeoapi in downstream applications Search Engine Optimization (SEO) Security and access control Semantic Web and Linked Data Cloud deployment INSPIRE support","title":"Advanced topics"},{"location":"advanced/#advanced-topics","text":"In this section, we will discuss more advanced pygeoapi topics primarily focused on extending pygeoapi via custom development and deployment. Multilingual support UI customization and templating Using pygeoapi in downstream applications Search Engine Optimization (SEO) Security and access control Semantic Web and Linked Data Cloud deployment INSPIRE support","title":"Advanced topics"},{"location":"advanced/cloud/","text":"Cloud deployment Deployment to cloud infratructure and concepts such as Microservices and Twelve-Factor present specific requirements to how software is designed and implemented. pygeoapi supports these concepts, having a low footprint on CPU and memory, and does not persist user state, therefore being able to scale without risks. pygeoapi and Docker A Docker image is available for pygeoapi. You can run the image locally as: docker run -p 5000 :80 https://hub.docker.com/r/geopython/pygeoapi:latest Review the pygeoapi docker file Notice in the pygeoapi docker file how the open api file is generated as part of the docker startup script. In a typical configuration one would override the default pygeoapi configuration file in the image with a customized one and include the data folder docker run -p 5000 :80 \\ -v $( pwd ) /pygeoapi-config.yml:/pygeoapi/local.config.yml \\ -v $( pwd ) /geodata:/geodata https://hub.docker.com/r/geopython/pygeoapi:latest Alternatively, you can build a fresh Docker image including both the configuration and data for the service. FROM geopython/pygeoapi:latest COPY ./my.config.yml /pygeoapi/local.config.yml You may have noticed that the pygeoapi configuration file includes a reference to the endpoint on which pygeoapi is published. This configuration should match the public endpoint of the service (domain, path and port). By default the pygeoapi Docker Image will run from the root path / . If you need to run from a sub-path and have all internal URLs correct you can set the SCRIPT_NAME environment variable. docker run -p 5000 :80 -e SCRIPT_NAME = '/mypygeoapi' \\ -v $( pwd ) /my.config.yml:/pygeoapi/local.config.yml -it geopython/pygeoapi # browse to http://localhost:5000/mypygeoapi Summary Congratulations! You can now deploy pygeopi as a cloud native service.","title":"Cloud deployment"},{"location":"advanced/cloud/#cloud-deployment","text":"Deployment to cloud infratructure and concepts such as Microservices and Twelve-Factor present specific requirements to how software is designed and implemented. pygeoapi supports these concepts, having a low footprint on CPU and memory, and does not persist user state, therefore being able to scale without risks.","title":"Cloud deployment"},{"location":"advanced/cloud/#pygeoapi-and-docker","text":"A Docker image is available for pygeoapi. You can run the image locally as: docker run -p 5000 :80 https://hub.docker.com/r/geopython/pygeoapi:latest Review the pygeoapi docker file Notice in the pygeoapi docker file how the open api file is generated as part of the docker startup script. In a typical configuration one would override the default pygeoapi configuration file in the image with a customized one and include the data folder docker run -p 5000 :80 \\ -v $( pwd ) /pygeoapi-config.yml:/pygeoapi/local.config.yml \\ -v $( pwd ) /geodata:/geodata https://hub.docker.com/r/geopython/pygeoapi:latest Alternatively, you can build a fresh Docker image including both the configuration and data for the service. FROM geopython/pygeoapi:latest COPY ./my.config.yml /pygeoapi/local.config.yml You may have noticed that the pygeoapi configuration file includes a reference to the endpoint on which pygeoapi is published. This configuration should match the public endpoint of the service (domain, path and port). By default the pygeoapi Docker Image will run from the root path / . If you need to run from a sub-path and have all internal URLs correct you can set the SCRIPT_NAME environment variable. docker run -p 5000 :80 -e SCRIPT_NAME = '/mypygeoapi' \\ -v $( pwd ) /my.config.yml:/pygeoapi/local.config.yml -it geopython/pygeoapi # browse to http://localhost:5000/mypygeoapi","title":"pygeoapi and Docker"},{"location":"advanced/cloud/#summary","text":"Congratulations! You can now deploy pygeopi as a cloud native service.","title":"Summary"},{"location":"advanced/downstream-applications/","text":"Using pygeoapi in downstream applications While pygeoapi is typically run as a standalone application, it is also designed to enable direct usage via external Python applications in a number of different design patterns.at multiple levels. From the official documentation , the below diagram provides an overview of how pygeoapi is designed and architected: There are two main ways to create a downstream application: Using the core API Extending through the web interface of the frameworks supported out-of-the box Using the core API directly The core pygeoapi Python API entrypoint is pygeoapi.api.API , which is initialized with the pygeoapi configuration as a Python dict . Note The pygeoapi core API enables the developer to manage pygeoapi configuration in any number of ways (file on disk, object storage, database driven, etc.) From here, API objects provide a number of functions, most of which require a pygeoapi.api.APIRequest object according to the web framework. Examples include: Flask Starlette FastAPI Django Note See the official documentation for more information about pygeoapi.api.APIRequest (you can even use your own custom request object as long as it satisfies the interface requirements of pygeoapi.api.APIRequest . Let's take a look at what a bare bones API integration would look like, using Flask as an example: from flask import Flask , make_response , request from pygeoapi.api import API from pygeoapi.util import yaml_load my_flask_app = Flask ( __name__ ) with open ( 'my-pygeoapi-config.yml' ) as fh : my_pygeoapi_config = yaml_load ( fh ) my_pygeoapi_api = API ( my_pygeoapi_config ) @my_flask_app . route ( '/my-landing-page-route' ) def my_def (): headers , status , content = my_pygeoapi_api . landing_page ( request ) response = make_response ( content , status ) if headers : response . headers = headers return response Note See the official documentation for more information on the core Python API Extending through a web framework pygeoapi can be installed and used at the web routing level as a dependency in your project. This is pretty much the easier way to leverage the flexibility and the modularity of its architecture. Once the interfaces are available then the developer can use the preferred framework for serving the frontend application. In practice the following modules: pygeoapi.flask_app.py for Flask blueprints pygeoapi.starlette_app.py for Starlette/FastAPI pygeoapi.django_app.py for Django (ongoing PR ) Some examples are available below for developers. Examples Flask blueprints from flask import Flask from pygeoapi.flask_app import BLUEPRINT as pygeoapi_blueprint my_flask_app = Flask ( __name__ , static_url_path = '/static' ) my_flask_app . url_map . strict_slashes = False # mount all pygeoapi endpoints to /oapi my_flask_app . register_blueprint ( pygeoapi_blueprint , url_prefix = '/oapi' ) @my_flask_app . route ( '/' ) def home (): return '<p>home page</p>' Starlette and FastAPI import uvicorn from fastapi import FastAPI from fastapi.exceptions import RequestValidationError from starlette.exceptions import HTTPException as StarletteHTTPException from starlette.middleware.cors import CORSMiddleware from pygeoapi.starlette_app import app as pygeoapi_app def create_app () -> FastAPI : \"\"\"Handle application creation.\"\"\" app = FastAPI ( title = \"my_pygeoapi\" , root_path = \"\" , debug = True ) # Set all CORS enabled origins app . add_middleware ( CORSMiddleware , allow_origins = [ \"*\" ], allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) @app . exception_handler ( StarletteHTTPException ) async def custom_http_exception_handler ( request , e ): return await http_exception_handler ( request , e ) @app . exception_handler ( RequestValidationError ) async def custom_validation_exception_handler ( request , e ): return await request_validation_exception_handler ( request , e ) # mount all pygeoapi endpoints to /oapi app . mount ( path = \"/oapi\" , app = pygeoapi_app ) return app app = create_app () if __name__ == \"__main__\" : uvicorn . run ( app , port = 5000 )","title":"Using pygeoapi in downstream applications"},{"location":"advanced/downstream-applications/#using-pygeoapi-in-downstream-applications","text":"While pygeoapi is typically run as a standalone application, it is also designed to enable direct usage via external Python applications in a number of different design patterns.at multiple levels. From the official documentation , the below diagram provides an overview of how pygeoapi is designed and architected: There are two main ways to create a downstream application: Using the core API Extending through the web interface of the frameworks supported out-of-the box","title":"Using pygeoapi in downstream applications"},{"location":"advanced/downstream-applications/#using-the-core-api-directly","text":"The core pygeoapi Python API entrypoint is pygeoapi.api.API , which is initialized with the pygeoapi configuration as a Python dict . Note The pygeoapi core API enables the developer to manage pygeoapi configuration in any number of ways (file on disk, object storage, database driven, etc.) From here, API objects provide a number of functions, most of which require a pygeoapi.api.APIRequest object according to the web framework. Examples include: Flask Starlette FastAPI Django Note See the official documentation for more information about pygeoapi.api.APIRequest (you can even use your own custom request object as long as it satisfies the interface requirements of pygeoapi.api.APIRequest . Let's take a look at what a bare bones API integration would look like, using Flask as an example: from flask import Flask , make_response , request from pygeoapi.api import API from pygeoapi.util import yaml_load my_flask_app = Flask ( __name__ ) with open ( 'my-pygeoapi-config.yml' ) as fh : my_pygeoapi_config = yaml_load ( fh ) my_pygeoapi_api = API ( my_pygeoapi_config ) @my_flask_app . route ( '/my-landing-page-route' ) def my_def (): headers , status , content = my_pygeoapi_api . landing_page ( request ) response = make_response ( content , status ) if headers : response . headers = headers return response Note See the official documentation for more information on the core Python API","title":"Using the core API directly"},{"location":"advanced/downstream-applications/#extending-through-a-web-framework","text":"pygeoapi can be installed and used at the web routing level as a dependency in your project. This is pretty much the easier way to leverage the flexibility and the modularity of its architecture. Once the interfaces are available then the developer can use the preferred framework for serving the frontend application. In practice the following modules: pygeoapi.flask_app.py for Flask blueprints pygeoapi.starlette_app.py for Starlette/FastAPI pygeoapi.django_app.py for Django (ongoing PR ) Some examples are available below for developers.","title":"Extending through a web framework"},{"location":"advanced/downstream-applications/#examples","text":"","title":"Examples"},{"location":"advanced/downstream-applications/#flask-blueprints","text":"from flask import Flask from pygeoapi.flask_app import BLUEPRINT as pygeoapi_blueprint my_flask_app = Flask ( __name__ , static_url_path = '/static' ) my_flask_app . url_map . strict_slashes = False # mount all pygeoapi endpoints to /oapi my_flask_app . register_blueprint ( pygeoapi_blueprint , url_prefix = '/oapi' ) @my_flask_app . route ( '/' ) def home (): return '<p>home page</p>'","title":"Flask blueprints"},{"location":"advanced/downstream-applications/#starlette-and-fastapi","text":"import uvicorn from fastapi import FastAPI from fastapi.exceptions import RequestValidationError from starlette.exceptions import HTTPException as StarletteHTTPException from starlette.middleware.cors import CORSMiddleware from pygeoapi.starlette_app import app as pygeoapi_app def create_app () -> FastAPI : \"\"\"Handle application creation.\"\"\" app = FastAPI ( title = \"my_pygeoapi\" , root_path = \"\" , debug = True ) # Set all CORS enabled origins app . add_middleware ( CORSMiddleware , allow_origins = [ \"*\" ], allow_credentials = True , allow_methods = [ \"*\" ], allow_headers = [ \"*\" ], ) @app . exception_handler ( StarletteHTTPException ) async def custom_http_exception_handler ( request , e ): return await http_exception_handler ( request , e ) @app . exception_handler ( RequestValidationError ) async def custom_validation_exception_handler ( request , e ): return await request_validation_exception_handler ( request , e ) # mount all pygeoapi endpoints to /oapi app . mount ( path = \"/oapi\" , app = pygeoapi_app ) return app app = create_app () if __name__ == \"__main__\" : uvicorn . run ( app , port = 5000 )","title":"Starlette and FastAPI"},{"location":"advanced/i18n/","text":"Multilingual support pygeoapi supports multilinguality at three levels: In the pygeoapi configuration you can provide titles and abstracts of the service and collections in multiple languages. A set of translatable text-strings which are translated and introduced as part of the JSON and HTML output formats. Translations are managed by the Babel framework Column names/values in feature based datasets. If a dataset contains columns in multiple languages, pygeoapi will try to return data responses in the requested language Note Error messages are not translated, to facilitate copy-paste of the error into stackoverflow and GitHub issues . Language negotiation is triggered by the HTTP Accept-Language header as sent by the client, and can always be overridden with the ?lang=fr url parameter. Multilingual configuration In the pygeoapi configuration you can indicate the languages supported by the instance. The first language is the default language. For most of the textual configuration properties you can provide a translation in alternative languages. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 lakes : type : collection title : en : Large Lakes fr : Grands Lacs description : en : lakes of the world, public domain fr : lacs du monde, domaine public keywords : en : - lakes - water bodies fr : - lacs - plans d'eau Text strings within Jinja2 HTML templates Most of the translatable text strings exist within the Jinja2 HTML templates. Text strings to be translated are placed in a trans tag, as follows: 1 < title > {% trans %}Page title{% endtrans %} </ title > Babel provides a utility which extracts all keys to be translated from the templates into a single .pot file. pybabel extract -F babel-mapping.ini -o locale/messages.pot ./ The resulting .pot file is used to create or update existing .po files, which exist for each language, containing the actual translations. pybabel init -d locale -l it -i locale/messages.pot The .po files are stored in pygeoapi's source code repository on GitHub. You can create a Pull Request to add or update your favourite languages. .po files can also be added to translation software such as transifex.com . Edit a .po file Open a .po file from the locale folder in a text editor. Edit some values. Save the file and restart the service. Verify that the updated content is available. You can also try to add a new key to a template and translate it via the .po mechanism. Annotating the language of data columns pygeoapi includes a meachanism to influence the API responses based on the requested language. If your service operates with multilingual requirements, it may make sense to add textual columns in multiple languages. For example, in the pygeoapi configuration you can then indicate which column should be used as the title field, for which language. Publish a multilingual dataset For this workshop we have prepared a multilingual dataset of free wifi hotspots in Florence ( workshop/exercises/data/free-wifi-florence.csv ). Add the dataset to the pygeoapi configuration using the CSV provider. Add a title-field configuration with for each translated column the relevant language. 1 2 3 4 5 6 data : /data/free-wifi-florence.csv id_field : id title_field : en : name-en it : name-it de : name-de Test the configuration by navigating to the items page of the collection and switching the language by appending ?lang=it , ?lang=de to the URL. Summary Congratulations! You've customized pygeoapi to support multiple languages.","title":"Multilingual support"},{"location":"advanced/i18n/#multilingual-support","text":"pygeoapi supports multilinguality at three levels: In the pygeoapi configuration you can provide titles and abstracts of the service and collections in multiple languages. A set of translatable text-strings which are translated and introduced as part of the JSON and HTML output formats. Translations are managed by the Babel framework Column names/values in feature based datasets. If a dataset contains columns in multiple languages, pygeoapi will try to return data responses in the requested language Note Error messages are not translated, to facilitate copy-paste of the error into stackoverflow and GitHub issues . Language negotiation is triggered by the HTTP Accept-Language header as sent by the client, and can always be overridden with the ?lang=fr url parameter.","title":"Multilingual support"},{"location":"advanced/i18n/#multilingual-configuration","text":"In the pygeoapi configuration you can indicate the languages supported by the instance. The first language is the default language. For most of the textual configuration properties you can provide a translation in alternative languages. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 lakes : type : collection title : en : Large Lakes fr : Grands Lacs description : en : lakes of the world, public domain fr : lacs du monde, domaine public keywords : en : - lakes - water bodies fr : - lacs - plans d'eau","title":"Multilingual configuration"},{"location":"advanced/i18n/#text-strings-within-jinja2-html-templates","text":"Most of the translatable text strings exist within the Jinja2 HTML templates. Text strings to be translated are placed in a trans tag, as follows: 1 < title > {% trans %}Page title{% endtrans %} </ title > Babel provides a utility which extracts all keys to be translated from the templates into a single .pot file. pybabel extract -F babel-mapping.ini -o locale/messages.pot ./ The resulting .pot file is used to create or update existing .po files, which exist for each language, containing the actual translations. pybabel init -d locale -l it -i locale/messages.pot The .po files are stored in pygeoapi's source code repository on GitHub. You can create a Pull Request to add or update your favourite languages. .po files can also be added to translation software such as transifex.com . Edit a .po file Open a .po file from the locale folder in a text editor. Edit some values. Save the file and restart the service. Verify that the updated content is available. You can also try to add a new key to a template and translate it via the .po mechanism.","title":"Text strings within Jinja2 HTML templates"},{"location":"advanced/i18n/#annotating-the-language-of-data-columns","text":"pygeoapi includes a meachanism to influence the API responses based on the requested language. If your service operates with multilingual requirements, it may make sense to add textual columns in multiple languages. For example, in the pygeoapi configuration you can then indicate which column should be used as the title field, for which language. Publish a multilingual dataset For this workshop we have prepared a multilingual dataset of free wifi hotspots in Florence ( workshop/exercises/data/free-wifi-florence.csv ). Add the dataset to the pygeoapi configuration using the CSV provider. Add a title-field configuration with for each translated column the relevant language. 1 2 3 4 5 6 data : /data/free-wifi-florence.csv id_field : id title_field : en : name-en it : name-it de : name-de Test the configuration by navigating to the items page of the collection and switching the language by appending ?lang=it , ?lang=de to the URL.","title":"Annotating the language of data columns"},{"location":"advanced/i18n/#summary","text":"Congratulations! You've customized pygeoapi to support multiple languages.","title":"Summary"},{"location":"advanced/inspire/","text":"INSPIRE support INSPIRE is a European directive on data sharing in the environmental domain. EU member states have invested almost 20 years of effort to harmonize data in the environmental domain and publish it using OGC standards. The directive is at the end of its lifetime, but the expectation is that conventions from the INSPIRE directive will be adopted by upcoming directives, such as green deal and open data directives. In the past 20 years, the IT landscape has changed considerably. INSPIRE has followed these developments by adopting a series of Good Practices which supersede the original Technical Guidelines . Some of the recent and upcoming good practices focus on the developments in the OGC API domain. One good practice has already been adopted on providing download services using OGC API - Features and others are in preparation, such as the discovery service using OGC API - Records . These developments make pygeoapi an interesting option for providing INSPIRE services. INSPIRE services and their OGC API alternative INSPIRE services are typically categorized in view services, download services and discovery services. Download services are further devided in Vector sources, Coverage sources and Sensor sources. The OGC API initiative provides the related APIs for each service. The table below highlights for each service type the Technical Guidenace recommendation and the relevant Good Practices. Service type TG OGC API Good practice status Discovery service CSW OGC API - Records In preparation View service WM(T)S OGC API - Maps / OGC API - Tiles Not scheduled In preparation Download service - Vector WFS OGC API - Features Adopted Download service - Coverage WCS OGC API - Coverages / STAC Not scheduled In preparation Download service - Sensor SOS OGC API - EDR / Sensorthings API 1 Not scheduled Adopted Note When adopting Good Practices, consider that the documentation and tools for validation are still limited. Also the INSPIRE GeoPortal may not be ready to harvest records from an OGC API - Records endpoint yet. Publish metadata documents as an INSPIRE discovery service In this exercise we will import a folder of metadata documents into a TinyDB database and configure the database as an OGC API - Records endpoint. Download the zipfile 'inspire-records.zip' from the repository. Expand the zipfile. The /tests folder contains a script load_tinydb_records.py . The script has 2 parameters: python3 load_tinydb_records.py <path/to/xml-files> <output.db> Now configure TinyDB as a provider for OGC API - Records . Restart the service and verify the result. Verify also the XML output of some of the records. OGC API and the INSPIRE data models Most of the INSPIRE data models have a hierarchical structure, which is not common in the GeoJSON oriented OGC API community. In theory it is possible to provide hierarchical GML from an OGC API endpoint, but there are not many experiences yet currently. Two initiatives may bring improvement to this aspect: pygeoapi facilitates to configure a JSON-LD encoding using an arbitrary ontology. The good practice on semantic web provides some of the data models in an RDF ontology The good practice on alternative encodings suggests an approach to publish datasets using a relational data model such as GeoPackage, which fits better with the OGC API community OGC API as a codelist registry A typical use case in INSPIRE is the option to extend an INSPIRE codelist to match a local requirement. For this use case the extended codelist has to be published in a registry. OGC API - Common provides mechanisms to publish lists of concepts as items in collections. pygeoapi also provides a mechanism to advertise the concepts using the SKOS ontology via its JSON-LD encoding. In the coincidence that a concept has a geometry property, the codelist can even be published as OGC API - Features (on a map). Publish a codelist via OGC API A German Soiltype codelist has been made available in CSV format in workshop/exercises/data/bodenart.en.csv . Use the CSV provider to publish this dataset in pygeoapi. Which URL would you use to reference a concept in the published list? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 SoilTypes : type : collection title : Soil types of Germany description : Bodenarten auf Basis der Bodenkundlichen Kartieranleitung 5. Auflage (KA5) keywords : - soiltype links : - type : text/html rel : canonical title : Soil types of Germany href : https://registry.gdi-de.org/codelist/de.bund.thuenen/bodenart hreflang : de extents : spatial : bbox : [ 0 , 0 , 0 , 0 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers : - type : feature name : CSV data : /data/bodenart.en.csv id_field : Label geometry : x_field : x y_field : y Summary Congratulations! You have worked with pygeoapi for INSPIRE compliance Sensorthings API and is not an OGC API standards and is currently not supported by pygeoapi. It is listed here for completeness \u21a9 STAC is not OGC API standard but is supported by pygeoapi \u21a9","title":"INSPIRE support"},{"location":"advanced/inspire/#inspire-support","text":"INSPIRE is a European directive on data sharing in the environmental domain. EU member states have invested almost 20 years of effort to harmonize data in the environmental domain and publish it using OGC standards. The directive is at the end of its lifetime, but the expectation is that conventions from the INSPIRE directive will be adopted by upcoming directives, such as green deal and open data directives. In the past 20 years, the IT landscape has changed considerably. INSPIRE has followed these developments by adopting a series of Good Practices which supersede the original Technical Guidelines . Some of the recent and upcoming good practices focus on the developments in the OGC API domain. One good practice has already been adopted on providing download services using OGC API - Features and others are in preparation, such as the discovery service using OGC API - Records . These developments make pygeoapi an interesting option for providing INSPIRE services.","title":"INSPIRE support"},{"location":"advanced/inspire/#inspire-services-and-their-ogc-api-alternative","text":"INSPIRE services are typically categorized in view services, download services and discovery services. Download services are further devided in Vector sources, Coverage sources and Sensor sources. The OGC API initiative provides the related APIs for each service. The table below highlights for each service type the Technical Guidenace recommendation and the relevant Good Practices. Service type TG OGC API Good practice status Discovery service CSW OGC API - Records In preparation View service WM(T)S OGC API - Maps / OGC API - Tiles Not scheduled In preparation Download service - Vector WFS OGC API - Features Adopted Download service - Coverage WCS OGC API - Coverages / STAC Not scheduled In preparation Download service - Sensor SOS OGC API - EDR / Sensorthings API 1 Not scheduled Adopted Note When adopting Good Practices, consider that the documentation and tools for validation are still limited. Also the INSPIRE GeoPortal may not be ready to harvest records from an OGC API - Records endpoint yet. Publish metadata documents as an INSPIRE discovery service In this exercise we will import a folder of metadata documents into a TinyDB database and configure the database as an OGC API - Records endpoint. Download the zipfile 'inspire-records.zip' from the repository. Expand the zipfile. The /tests folder contains a script load_tinydb_records.py . The script has 2 parameters: python3 load_tinydb_records.py <path/to/xml-files> <output.db> Now configure TinyDB as a provider for OGC API - Records . Restart the service and verify the result. Verify also the XML output of some of the records.","title":"INSPIRE services and their OGC API alternative"},{"location":"advanced/inspire/#ogc-api-and-the-inspire-data-models","text":"Most of the INSPIRE data models have a hierarchical structure, which is not common in the GeoJSON oriented OGC API community. In theory it is possible to provide hierarchical GML from an OGC API endpoint, but there are not many experiences yet currently. Two initiatives may bring improvement to this aspect: pygeoapi facilitates to configure a JSON-LD encoding using an arbitrary ontology. The good practice on semantic web provides some of the data models in an RDF ontology The good practice on alternative encodings suggests an approach to publish datasets using a relational data model such as GeoPackage, which fits better with the OGC API community","title":"OGC API and the INSPIRE data models"},{"location":"advanced/inspire/#ogc-api-as-a-codelist-registry","text":"A typical use case in INSPIRE is the option to extend an INSPIRE codelist to match a local requirement. For this use case the extended codelist has to be published in a registry. OGC API - Common provides mechanisms to publish lists of concepts as items in collections. pygeoapi also provides a mechanism to advertise the concepts using the SKOS ontology via its JSON-LD encoding. In the coincidence that a concept has a geometry property, the codelist can even be published as OGC API - Features (on a map). Publish a codelist via OGC API A German Soiltype codelist has been made available in CSV format in workshop/exercises/data/bodenart.en.csv . Use the CSV provider to publish this dataset in pygeoapi. Which URL would you use to reference a concept in the published list? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 SoilTypes : type : collection title : Soil types of Germany description : Bodenarten auf Basis der Bodenkundlichen Kartieranleitung 5. Auflage (KA5) keywords : - soiltype links : - type : text/html rel : canonical title : Soil types of Germany href : https://registry.gdi-de.org/codelist/de.bund.thuenen/bodenart hreflang : de extents : spatial : bbox : [ 0 , 0 , 0 , 0 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers : - type : feature name : CSV data : /data/bodenart.en.csv id_field : Label geometry : x_field : x y_field : y","title":"OGC API as a codelist registry"},{"location":"advanced/inspire/#summary","text":"Congratulations! You have worked with pygeoapi for INSPIRE compliance Sensorthings API and is not an OGC API standards and is currently not supported by pygeoapi. It is listed here for completeness \u21a9 STAC is not OGC API standard but is supported by pygeoapi \u21a9","title":"Summary"},{"location":"advanced/security-access-control/","text":"Security and access control Security in general is a broad and complex topic, affecting the entire development lifecycle. It is recommended to follow security best practices during all development phases like design, coding and deployment. In this workshop we will focus only on API security and access control, rather than the full range of application security topics. Application Security The Open Web Application Security Project (OWASP) Top Ten document is a very good tool to ensure the bare minimum against the security risks and manage critical treats that are most likely affecting your code. API Security is the whole process to protect APIs from attacks. It is part of the more general security guidelines that are being treated in the OWASP Top Ten document. So those recommendations still apply. Access control is another fundamental part of the Open Web Application Security Project and addresses the Identity and Access Management (IAM) of an API. IAM consists of two different parts of a security flow: Authentication (AuthN) verifies the user's identity in order to allow or deny subsequent access (see next) Authorization (AuthZ) validates permissions of a user (identity) to access a resource. The permissions of that identity are checked against a resource's policies to (dis)allow access to, for example, (parts of) an API. These parts are usually managed by dedicated infrastructures and solutions which usually provide most of the security requirements out-of-the-box. OpenAPI Security Specification The OpenAPI specification has very well-defined elements for developers and adopters. The most relevant are: - Security Scheme Object defines the security schemes that can be used by the operations. Supported schemes are HTTP Authentication , an API Key , OAuth2 's flows and OpenID Connect . - Security Requirement Object defines the list of required security schemes to execute an operation.","title":"Security and access control"},{"location":"advanced/security-access-control/#security-and-access-control","text":"Security in general is a broad and complex topic, affecting the entire development lifecycle. It is recommended to follow security best practices during all development phases like design, coding and deployment. In this workshop we will focus only on API security and access control, rather than the full range of application security topics. Application Security The Open Web Application Security Project (OWASP) Top Ten document is a very good tool to ensure the bare minimum against the security risks and manage critical treats that are most likely affecting your code. API Security is the whole process to protect APIs from attacks. It is part of the more general security guidelines that are being treated in the OWASP Top Ten document. So those recommendations still apply. Access control is another fundamental part of the Open Web Application Security Project and addresses the Identity and Access Management (IAM) of an API. IAM consists of two different parts of a security flow: Authentication (AuthN) verifies the user's identity in order to allow or deny subsequent access (see next) Authorization (AuthZ) validates permissions of a user (identity) to access a resource. The permissions of that identity are checked against a resource's policies to (dis)allow access to, for example, (parts of) an API. These parts are usually managed by dedicated infrastructures and solutions which usually provide most of the security requirements out-of-the-box. OpenAPI Security Specification The OpenAPI specification has very well-defined elements for developers and adopters. The most relevant are: - Security Scheme Object defines the security schemes that can be used by the operations. Supported schemes are HTTP Authentication , an API Key , OAuth2 's flows and OpenID Connect . - Security Requirement Object defines the list of required security schemes to execute an operation.","title":"Security and access control"},{"location":"advanced/semantic-web-linked-data/","text":"Semantic Web and Linked Data This section touches on 3 aspects of the Semantic Web: Search engines Publish spatial data in the semantic web Proxy to semantic web Search engines Search engines use technology similar to the Semantic Web to facilitate capturing structured data (aka rich snippets) from web pages. pygeoapi supports this use case via embedding a schema.org JSON-LD snippet in the HTML encoding, Tip The schema.org ontology is not a formal Semantic Web ontology, it is therefore a bit disconnected from the rest of the Semantic Web Tip See more information at Search Engine Optimization Publish spatial data in the Semantic Web OGC API - Common adopted a number of W3C conventions, which bring OGC APIs closer to the standards of Semantic Web, compared to first generation OGC Web Service (OWS) standards. Currently, pygeaopi does not aim to be a full implementation of Semantic Web, however it is possible to advertise some aspects of the Semantic Web so the data can be traversed by Semantic Web aware clients. Use a SPARQL client to query pygeoapi SPARQL is commonly known as the query language to query triple stores. However you can also use SPARQL to query graphs of linked web resources. The SPARQL client traverses links between the resources to locate the requested triples. Jena ARQ is a command line SPARQL client which is able to run such queries. Jena is quite difficult to set up, although there is a Docker Image available. As an alternative we will use a web-based implementation of the ARQ engine. Navigate to https://demos.isl.ics.forth.gr/sparql-ld-endpoint and replace the query in the textbox with: 1 2 3 4 5 6 7 SELECT * WHERE { SERVICE < https : // demo . pygeoapi . io / master / collections / lakes > { { ? s ? p ? o } } } A query to an item returns the item with its geometry: 1 2 3 4 5 SELECT * WHERE { SERVICE < https : // demo . pygeoapi . io / master / collections / lakes / items / 1 > { {{ ? s ? p ? o }} } } Notice that the SPARQL client fails if you hardcode the HTML format. 1 2 3 4 5 SELECT * WHERE { SERVICE < https : // demo . pygeoapi . io / master / collections / lakes ? f = html > { { ? s ? p ? o } } } JSON-LD as expected by search engines has some challenges for semantic web tools. So how does it work if the format is not hardcoded? The SPARQL engine negotiates with the endpoint to evaluate which (RDF) encodings are available, and based on the content negotiation it requests the JSON_LD encoding via f=jsonld . pygeoapi adopted conventions of the JSON-LD community to annotate JSON as RDF. For features, each property (column in a source table) is annotated by a semantic concept. The related configuration to apply the annotations is managed in the context element of a resource definition Tip Read more in the pygeoapi documentation . 1 2 3 4 5 6 7 8 9 context : - schema : https://schema.org/ stn_id : schema:identifer datetime : \"@id\" : schema:observationDate \"@type\" : schema:DateTime value : \"@id\" : schema:value \"@type\" : schema:Number Proxy to the Semantic Web Spatial data engineers are generally challenged when importing and visualizing fragments of the semantic web. The number of spatial clients currently supporting SQARQL interaction is limited and requires expert knowledge to use. A group within the pygeoapi community aims to facilitate semantic web access for spatial data engineers by introducing pygeoapi as a proxy between the typical GIS clients and the semantic web. A new feature is being prepared which introduces a SPARQL provider to pygeoapi. The provider enables to browse the results of a SPARQL query as an OGC API - Features collection. Summary Congratulations! You can now configure pygeoapi configurations with linked data concepts.","title":"Semantic Web and Linked Data"},{"location":"advanced/semantic-web-linked-data/#semantic-web-and-linked-data","text":"This section touches on 3 aspects of the Semantic Web: Search engines Publish spatial data in the semantic web Proxy to semantic web","title":"Semantic Web and Linked Data"},{"location":"advanced/semantic-web-linked-data/#search-engines","text":"Search engines use technology similar to the Semantic Web to facilitate capturing structured data (aka rich snippets) from web pages. pygeoapi supports this use case via embedding a schema.org JSON-LD snippet in the HTML encoding, Tip The schema.org ontology is not a formal Semantic Web ontology, it is therefore a bit disconnected from the rest of the Semantic Web Tip See more information at Search Engine Optimization","title":"Search engines"},{"location":"advanced/semantic-web-linked-data/#publish-spatial-data-in-the-semantic-web","text":"OGC API - Common adopted a number of W3C conventions, which bring OGC APIs closer to the standards of Semantic Web, compared to first generation OGC Web Service (OWS) standards. Currently, pygeaopi does not aim to be a full implementation of Semantic Web, however it is possible to advertise some aspects of the Semantic Web so the data can be traversed by Semantic Web aware clients. Use a SPARQL client to query pygeoapi SPARQL is commonly known as the query language to query triple stores. However you can also use SPARQL to query graphs of linked web resources. The SPARQL client traverses links between the resources to locate the requested triples. Jena ARQ is a command line SPARQL client which is able to run such queries. Jena is quite difficult to set up, although there is a Docker Image available. As an alternative we will use a web-based implementation of the ARQ engine. Navigate to https://demos.isl.ics.forth.gr/sparql-ld-endpoint and replace the query in the textbox with: 1 2 3 4 5 6 7 SELECT * WHERE { SERVICE < https : // demo . pygeoapi . io / master / collections / lakes > { { ? s ? p ? o } } } A query to an item returns the item with its geometry: 1 2 3 4 5 SELECT * WHERE { SERVICE < https : // demo . pygeoapi . io / master / collections / lakes / items / 1 > { {{ ? s ? p ? o }} } } Notice that the SPARQL client fails if you hardcode the HTML format. 1 2 3 4 5 SELECT * WHERE { SERVICE < https : // demo . pygeoapi . io / master / collections / lakes ? f = html > { { ? s ? p ? o } } } JSON-LD as expected by search engines has some challenges for semantic web tools. So how does it work if the format is not hardcoded? The SPARQL engine negotiates with the endpoint to evaluate which (RDF) encodings are available, and based on the content negotiation it requests the JSON_LD encoding via f=jsonld . pygeoapi adopted conventions of the JSON-LD community to annotate JSON as RDF. For features, each property (column in a source table) is annotated by a semantic concept. The related configuration to apply the annotations is managed in the context element of a resource definition Tip Read more in the pygeoapi documentation . 1 2 3 4 5 6 7 8 9 context : - schema : https://schema.org/ stn_id : schema:identifer datetime : \"@id\" : schema:observationDate \"@type\" : schema:DateTime value : \"@id\" : schema:value \"@type\" : schema:Number","title":"Publish spatial data in the Semantic Web"},{"location":"advanced/semantic-web-linked-data/#proxy-to-the-semantic-web","text":"Spatial data engineers are generally challenged when importing and visualizing fragments of the semantic web. The number of spatial clients currently supporting SQARQL interaction is limited and requires expert knowledge to use. A group within the pygeoapi community aims to facilitate semantic web access for spatial data engineers by introducing pygeoapi as a proxy between the typical GIS clients and the semantic web. A new feature is being prepared which introduces a SPARQL provider to pygeoapi. The provider enables to browse the results of a SPARQL query as an OGC API - Features collection.","title":"Proxy to the Semantic Web"},{"location":"advanced/semantic-web-linked-data/#summary","text":"Congratulations! You can now configure pygeoapi configurations with linked data concepts.","title":"Summary"},{"location":"advanced/seo/","text":"Search Engine Optimization (SEO) OGC API - Features adopted the Spatial Data on the Web Best Practice 2: Make your spatial data indexable by search engines with the recommendation to include HTML as an output format of any OGC API . It means that users can navigate an OGC API from within their browser and Search Engines are able to crawl the content. An aspect to consider is that, since the API becomes a webpage, common practices for web architecture and development become relevant: does the website have a clear navigation? is a company logo, branding, privacy statement, cookie warning included? is the webpage WCAG accessable? Tip Notice that the pygeoapi configuration also has an option to disable HTML output. In that scenario, only the JSON output is available. On the Web, websites are typically visited by web crawlers of popular search engines. Crawlers are automated processes which aid in building the index of the search engine. Crawlers follow links on the Web to identify new or updated content. Cross linking your API to other resources therefore increases the visibility (and ranking) of your API. The British Geo6 wrote an extensive best practice on SEO for data publishers which offers a good overview of SEO in the scope of data publications. Tweaking Web Crawler behaviour This paragraph introduces you to some mechanisms which facilitate or block web crawlers to index your content. If you are not interested in having your content indexed by search engines, you can provide a robots.txt file at the root of your website, specifying which folders should not be indexed. More drastically is the option to block access for crawlers or bots to your content by filtering traffic to the website based on the HTTP User-Agent header . Such a rule can be added to a firewall or web server configuration. A robots.txt file can also include a link to a Sitemap . Many search engines provide the option to submit a sitemap in order to speed up crawling and indexing. pygeoapi does not provide a sitemap of its content, but you can create your own sitemap (publish as /sitemap.xml ), specifying URLs of your desired content to be indexed. Search engines provide tooling to evaluate the search behaviour of your website. These tools can provide valuable insight in the findability of your website and content (e.g. keywords used to locate your website). Schema.org/Dataset Search engines cooperate in the Schema.org initiative. Schema.org enables you to annotate your website using the schema.org vocabulaire, in order for search engines to index the content in a structured manner. Google was the first to employ these annotations to provide a dedicated search engine for datasets . pygeoapi adds schema.org/Dataset annotations to collection pages, so collections are automagically included in Google's dataset search. Evaluate the schema.org annotations in collections Google provides a tool to evaluate Schema.org annotation in websites. Try evaluating a collection endpoint of pygeoapi in the tool. If you run pygeoapi locally (not accessible to google), you can copy the source of a page as HTML into the <code> tab, otherwise you can paste the URL of the page in the URL tab. Note A similar tool is made available by Yandex (note that registration is required).","title":"Search Engine Optimization (SEO)"},{"location":"advanced/seo/#search-engine-optimization-seo","text":"OGC API - Features adopted the Spatial Data on the Web Best Practice 2: Make your spatial data indexable by search engines with the recommendation to include HTML as an output format of any OGC API . It means that users can navigate an OGC API from within their browser and Search Engines are able to crawl the content. An aspect to consider is that, since the API becomes a webpage, common practices for web architecture and development become relevant: does the website have a clear navigation? is a company logo, branding, privacy statement, cookie warning included? is the webpage WCAG accessable? Tip Notice that the pygeoapi configuration also has an option to disable HTML output. In that scenario, only the JSON output is available. On the Web, websites are typically visited by web crawlers of popular search engines. Crawlers are automated processes which aid in building the index of the search engine. Crawlers follow links on the Web to identify new or updated content. Cross linking your API to other resources therefore increases the visibility (and ranking) of your API. The British Geo6 wrote an extensive best practice on SEO for data publishers which offers a good overview of SEO in the scope of data publications.","title":"Search Engine Optimization (SEO)"},{"location":"advanced/seo/#tweaking-web-crawler-behaviour","text":"This paragraph introduces you to some mechanisms which facilitate or block web crawlers to index your content. If you are not interested in having your content indexed by search engines, you can provide a robots.txt file at the root of your website, specifying which folders should not be indexed. More drastically is the option to block access for crawlers or bots to your content by filtering traffic to the website based on the HTTP User-Agent header . Such a rule can be added to a firewall or web server configuration. A robots.txt file can also include a link to a Sitemap . Many search engines provide the option to submit a sitemap in order to speed up crawling and indexing. pygeoapi does not provide a sitemap of its content, but you can create your own sitemap (publish as /sitemap.xml ), specifying URLs of your desired content to be indexed. Search engines provide tooling to evaluate the search behaviour of your website. These tools can provide valuable insight in the findability of your website and content (e.g. keywords used to locate your website).","title":"Tweaking Web Crawler behaviour"},{"location":"advanced/seo/#schemaorgdataset","text":"Search engines cooperate in the Schema.org initiative. Schema.org enables you to annotate your website using the schema.org vocabulaire, in order for search engines to index the content in a structured manner. Google was the first to employ these annotations to provide a dedicated search engine for datasets . pygeoapi adds schema.org/Dataset annotations to collection pages, so collections are automagically included in Google's dataset search. Evaluate the schema.org annotations in collections Google provides a tool to evaluate Schema.org annotation in websites. Try evaluating a collection endpoint of pygeoapi in the tool. If you run pygeoapi locally (not accessible to google), you can copy the source of a page as HTML into the <code> tab, otherwise you can paste the URL of the page in the URL tab. Note A similar tool is made available by Yandex (note that registration is required).","title":"Schema.org/Dataset"},{"location":"advanced/ui-custom-templates/","text":"UI customization and templating pygeoapi adopted the Jinja2 templating mechanism to style HTML output. Each element visualized on the HTML output is customizable by overriding the relevant template. Templates are located in the pygeoapi/templates folder. It is possible to override any template by copying it into a separate folder and adjust it to your needs. In the pygeoapi configuration you can then indicate the path to the override folder. Notice that for files which are not placed in the override folder, the original file is used. Caution For any customization, mind that with a new version of pygeoapi changes on the default templates are not automatically available on the overriden files. Upgrades need to be carefully tested and validated. Jinja2 Jinja2 is a common templating concept in the Python community. With a minimal background in HTML you will be able to make minor but meaningful customizations. At the core of pygeoapi's template setup is the _base.html template, which defines the header and footer of the page. The fragment below defines the footer of the page, notice the parameters in curly braces, which are replaced by dynamic content. 1 2 3 4 5 6 < footer class = \"sticky\" > {% trans %}Powered by {% endtrans %} < a title = \"pygeoapi\" href = \"https://pygeoapi.io\" > < img src = \"{{ config['server']['url'] }}/assets/images/pygeoapi.png\" title = \"pygeoapi logo\" style = \"height:24px;vertical-align: middle;\" /></ a > {{ version }} </ footer > Customizing an HTML page Copy _base.html to a separate folder. Adjust some elements on that page (e.g. logo image). Then, include a reference to the new folder in the pygeoapi configuration. Restart the service. Verify the result. CSS customizations From the customized HTML template you can reference a new stylesheet file with customizations or directly add your customizations to /static/css/default.css . Summary Congratulations! You've added a custom look and feel to your pygeoapi deployment.","title":"UI customization and templating"},{"location":"advanced/ui-custom-templates/#ui-customization-and-templating","text":"pygeoapi adopted the Jinja2 templating mechanism to style HTML output. Each element visualized on the HTML output is customizable by overriding the relevant template. Templates are located in the pygeoapi/templates folder. It is possible to override any template by copying it into a separate folder and adjust it to your needs. In the pygeoapi configuration you can then indicate the path to the override folder. Notice that for files which are not placed in the override folder, the original file is used. Caution For any customization, mind that with a new version of pygeoapi changes on the default templates are not automatically available on the overriden files. Upgrades need to be carefully tested and validated.","title":"UI customization and templating"},{"location":"advanced/ui-custom-templates/#jinja2","text":"Jinja2 is a common templating concept in the Python community. With a minimal background in HTML you will be able to make minor but meaningful customizations. At the core of pygeoapi's template setup is the _base.html template, which defines the header and footer of the page. The fragment below defines the footer of the page, notice the parameters in curly braces, which are replaced by dynamic content. 1 2 3 4 5 6 < footer class = \"sticky\" > {% trans %}Powered by {% endtrans %} < a title = \"pygeoapi\" href = \"https://pygeoapi.io\" > < img src = \"{{ config['server']['url'] }}/assets/images/pygeoapi.png\" title = \"pygeoapi logo\" style = \"height:24px;vertical-align: middle;\" /></ a > {{ version }} </ footer > Customizing an HTML page Copy _base.html to a separate folder. Adjust some elements on that page (e.g. logo image). Then, include a reference to the new folder in the pygeoapi configuration. Restart the service. Verify the result.","title":"Jinja2"},{"location":"advanced/ui-custom-templates/#css-customizations","text":"From the customized HTML template you can reference a new stylesheet file with customizations or directly add your customizations to /static/css/default.css .","title":"CSS customizations"},{"location":"advanced/ui-custom-templates/#summary","text":"Congratulations! You've added a custom look and feel to your pygeoapi deployment.","title":"Summary"},{"location":"publishing/","text":"Publishing Data Note Ensure that you have pygeoapi setup and can navigate the default configuration and service ( http://localhost:5000 ). In this section, you will learn how to publish different types of geospatial data and metadata through the following exercises: Exercise 1 - Your first dataset Exercise 2 - Vector data via OGC API - Features Exercise 3 - Raster data via OGC API - Coverages Exercise 4 - Tiles of geospatial data via OGC API - Tiles Exercise 5 - Metadata via OGC API - Records Exercise 6 - Environmental data via OGC - Environmental Data Retrieval","title":"Publishing data"},{"location":"publishing/#publishing-data","text":"Note Ensure that you have pygeoapi setup and can navigate the default configuration and service ( http://localhost:5000 ). In this section, you will learn how to publish different types of geospatial data and metadata through the following exercises: Exercise 1 - Your first dataset Exercise 2 - Vector data via OGC API - Features Exercise 3 - Raster data via OGC API - Coverages Exercise 4 - Tiles of geospatial data via OGC API - Tiles Exercise 5 - Metadata via OGC API - Records Exercise 6 - Environmental data via OGC - Environmental Data Retrieval","title":"Publishing Data"},{"location":"publishing/first/","text":"Exercise 1 - Your first dataset In this section you are going to publish a vector dataset. For this exercise, we will use a CSV dataset of free Wifi locations in Florence , kindly provided by opendata.comune.fi.it . You can find this dataset in workshop/exercises/data/free-wifi-florence.csv . This exercise consists of two key steps: adapt the pygeoapi.config.yml to define this dataset as an OGC API - Features collection ensure that pygeoapi can find and connec to the data file We will use the docker-compose.yml file provided. Verify the existing Docker Compose config Before making any changes, we will make sure that the initial Docker Compose setup provided to you is actually working. Two files are relevant: workshop/exercises/docker-compose.yml pygeoapi/docker.pygeoapi.config To test: Test the workshop configuration In a terminal shell navigate to the workshop folder and type: docker-compose up 1. Open http://localhost:5000 in your browser, verify some collections 1. Close by typing CTRL-C Note You may also run the Docker container in the background (detached) as follows: docker-compose up -d docker ls # verify that the pygeoapi container is running # visit http://localhost:5000 in your browser, verify some collections docker logs --follow pygeoapi # view logs docker-compose stop Publish first dataset You are now ready to publish your first dataset. Setting up the pygeoapi config file Open the file workshop/exercises/pygeoapi/pygeoapi.config.yml in your text editor Look for the commented config section starting with # START - EXERCISE 1 - Your First Collection Uncomment all lines until # END - EXERCISE 1 - Your First Collection Make sure that the indentation aligns (hint: directly under `# START ...) The config section reads: 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 free_wifi_florence: type: collection title: Free WIFI Florence description: The dataset shows the location of the places in the Municipality of Florence where a free wireless internet connection service (Wifi) is available. keywords: - wifi - florence links: - type: text/csv rel: canonical title: data href: https://opendata.comune.fi.it/?q=metarepo/datasetinfo&id=fb5b7bac-bcb0-4326-9388-7e3f3d671d71 hreflang: it-IT extents: spatial: bbox: [11, 43.6, 11.4, 43.9] crs: http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers: - type: feature name: CSV data: /data/free-wifi-florence.csv id_field: name-it geometry: x_field: lon y_field: lat The most relevant part is the providers section. Here, we define a CSV Provider , pointing the file path to the /data directory we will mount (see next) from the local directory into the Docker container above. Because a CSV is not a spatial file, we explicitly configure pygeoapi so that the longitude and latitude (x and y) is mapped from the columns lon and lat in the CSV file. Tip To learn more about the pygeoapi configuration syntax and conventions see the relevant chapter in the documentation . Tip pygeoapi includes numerous data providers which enable access to a variety of data formats. Via the OGR/GDAL plugin the number of supported formats is almost limitless. Consult the data provider page how you can set up a connection to your dataset of choice. You can always copy a relevant example configuration and place it in the datasets section of the pygeoapi configuration file for your future project. Making data available in the Docker container As the Docker container (named pygeoapi ) cannot directly access files on your local host system, we will use Docker volume mounts. This can be defined in the docker-compose.yml file as follows: Configure access to the data Open the file workshop/exercises/docker-compose.yml Look for the commented section # Exercise 1 - Uncomment that line - ./data:/data The relevant lines read: 43 44 45 volumes: - ./pygeoapi/pygeoapi.config.yml:/pygeoapi/local.config.yml - ./data:/data # Exercise 1 - Ready to pull data from here The local ./pygeoapi/pygeoapi.config.yml file was already mounted. Now we have also mounted (made available) the entire local directory ./data . Test Start with updated configuration Start by typing docker-compose up Observe logging output If no errors: open http://localhost:5000 Look for the Free Wifi Collection Browse through the collection Debugging configuration errors Incidentally you may run into errors, briefly discussed here: A file cannot be found, a typo in the configuration The format or structure of the spatial file is not fully supported The port (5000) is already taken. Is a previous pygeoapi still running? If you change the port, consider that you also have to update the pygeoapi config file There are two parameters in the configuration file which help to address these issues. Set the logging level to DEBUG and indicate a path to a log file. Tip On Docker, set the path of the logfile to the mounted folder, so you can easily access it from your host system. You can also view the console logs from your Docker container as follows: docker logs --follow pygeoapi Tip Errors related to file paths typically happen on initial setup. However, they may also happen at unexpected moments, resulting in a broken service. Products such as GeoHealthCheck aim to monitor, detect and notify service health and availability. The OGC APi - Features tests in GeoHealthCheck poll the availability of the service at intervals. Consult the GeoHealthCheck documentation for more information.","title":"Exercise 1 - Your first dataset"},{"location":"publishing/first/#exercise-1-your-first-dataset","text":"In this section you are going to publish a vector dataset. For this exercise, we will use a CSV dataset of free Wifi locations in Florence , kindly provided by opendata.comune.fi.it . You can find this dataset in workshop/exercises/data/free-wifi-florence.csv . This exercise consists of two key steps: adapt the pygeoapi.config.yml to define this dataset as an OGC API - Features collection ensure that pygeoapi can find and connec to the data file We will use the docker-compose.yml file provided.","title":"Exercise 1 - Your first dataset"},{"location":"publishing/first/#verify-the-existing-docker-compose-config","text":"Before making any changes, we will make sure that the initial Docker Compose setup provided to you is actually working. Two files are relevant: workshop/exercises/docker-compose.yml pygeoapi/docker.pygeoapi.config To test: Test the workshop configuration In a terminal shell navigate to the workshop folder and type: docker-compose up 1. Open http://localhost:5000 in your browser, verify some collections 1. Close by typing CTRL-C Note You may also run the Docker container in the background (detached) as follows: docker-compose up -d docker ls # verify that the pygeoapi container is running # visit http://localhost:5000 in your browser, verify some collections docker logs --follow pygeoapi # view logs docker-compose stop","title":"Verify the existing Docker Compose config"},{"location":"publishing/first/#publish-first-dataset","text":"You are now ready to publish your first dataset. Setting up the pygeoapi config file Open the file workshop/exercises/pygeoapi/pygeoapi.config.yml in your text editor Look for the commented config section starting with # START - EXERCISE 1 - Your First Collection Uncomment all lines until # END - EXERCISE 1 - Your First Collection Make sure that the indentation aligns (hint: directly under `# START ...) The config section reads: 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 free_wifi_florence: type: collection title: Free WIFI Florence description: The dataset shows the location of the places in the Municipality of Florence where a free wireless internet connection service (Wifi) is available. keywords: - wifi - florence links: - type: text/csv rel: canonical title: data href: https://opendata.comune.fi.it/?q=metarepo/datasetinfo&id=fb5b7bac-bcb0-4326-9388-7e3f3d671d71 hreflang: it-IT extents: spatial: bbox: [11, 43.6, 11.4, 43.9] crs: http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers: - type: feature name: CSV data: /data/free-wifi-florence.csv id_field: name-it geometry: x_field: lon y_field: lat The most relevant part is the providers section. Here, we define a CSV Provider , pointing the file path to the /data directory we will mount (see next) from the local directory into the Docker container above. Because a CSV is not a spatial file, we explicitly configure pygeoapi so that the longitude and latitude (x and y) is mapped from the columns lon and lat in the CSV file. Tip To learn more about the pygeoapi configuration syntax and conventions see the relevant chapter in the documentation . Tip pygeoapi includes numerous data providers which enable access to a variety of data formats. Via the OGR/GDAL plugin the number of supported formats is almost limitless. Consult the data provider page how you can set up a connection to your dataset of choice. You can always copy a relevant example configuration and place it in the datasets section of the pygeoapi configuration file for your future project.","title":"Publish first dataset"},{"location":"publishing/first/#making-data-available-in-the-docker-container","text":"As the Docker container (named pygeoapi ) cannot directly access files on your local host system, we will use Docker volume mounts. This can be defined in the docker-compose.yml file as follows: Configure access to the data Open the file workshop/exercises/docker-compose.yml Look for the commented section # Exercise 1 - Uncomment that line - ./data:/data The relevant lines read: 43 44 45 volumes: - ./pygeoapi/pygeoapi.config.yml:/pygeoapi/local.config.yml - ./data:/data # Exercise 1 - Ready to pull data from here The local ./pygeoapi/pygeoapi.config.yml file was already mounted. Now we have also mounted (made available) the entire local directory ./data .","title":"Making data available in the Docker container"},{"location":"publishing/first/#test","text":"Start with updated configuration Start by typing docker-compose up Observe logging output If no errors: open http://localhost:5000 Look for the Free Wifi Collection Browse through the collection","title":"Test"},{"location":"publishing/first/#debugging-configuration-errors","text":"Incidentally you may run into errors, briefly discussed here: A file cannot be found, a typo in the configuration The format or structure of the spatial file is not fully supported The port (5000) is already taken. Is a previous pygeoapi still running? If you change the port, consider that you also have to update the pygeoapi config file There are two parameters in the configuration file which help to address these issues. Set the logging level to DEBUG and indicate a path to a log file. Tip On Docker, set the path of the logfile to the mounted folder, so you can easily access it from your host system. You can also view the console logs from your Docker container as follows: docker logs --follow pygeoapi Tip Errors related to file paths typically happen on initial setup. However, they may also happen at unexpected moments, resulting in a broken service. Products such as GeoHealthCheck aim to monitor, detect and notify service health and availability. The OGC APi - Features tests in GeoHealthCheck poll the availability of the service at intervals. Consult the GeoHealthCheck documentation for more information.","title":"Debugging configuration errors"},{"location":"publishing/ogccov/","text":"Exercise 3 - Raster data via OGC API - Coverages OGC API - Coverages provides a Web API to access raster data (grids, remote sensing data, multidimensional data cubes): OGC API - Coverages ( draft ) pygeoapi support pygeoapi supports the OGC API - Coverages draft specification, with rasterio and xarray as core backends and CoverageJSON and native output. Note See the official documentation for more information on supported raster backends Publish a raster dataset In the previous exercises we have demonstrated the steps involved to publish vector data and update the pygeoapi configuration. In this section we are going to publish a raster file in GeoTIFF format, from a rasterio source provider. Download and unzip the GeoTIFF file: cd workshop/exercises/data curl -O http://dati.cittametropolitana.fi.it/geonetwork/srv/api/records/cmfi:419774cb-e812-4ca4-991d-97f0b747e017/attachments/53.zip unzip 53 .zip You can now add 53_ED1_G.tif to pygeoapi: Update the pygeoapi configuration Open the pygeoapi configuration file in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 firenze-terrains : type : collection title : Administrative boundaries before 2014 description : Cadastral parcels (terrains) from the cadastre. Territory Agency; SIT and Information Networks; keywords : - Cadastral parcels links : - type : text/html rel : canonical title : Administrative boundaries before 2014 href : http://dati.cittametropolitana.fi.it/geonetwork/srv/metadata/cmfi:419774cb-e812-4ca4-991d-97f0b747e017 hreflang : it extents : spatial : bbox : [ 10.70 , 43.43 , 11.76 , 44.25 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers : - type : coverage name : rasterio data : /data/53_ED1_G.tif # place correct path here format : name : GTiff mimetype : application/tiff Tip The rasterio provider format.name directive requires a valid GDAL raster driver short name Save the configuration and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published. Client access GDAL/OGR GDAL/OGR provides support for OGC API - Coverages . This means you can use gdalinfo to query and convert data from OGC API - Coverages endpoints just like any other raster data source. This also means you can make connections to OGC API - Coverages endpoints from any software which has an interface to GDAL, such as MapServer, GeoServer, Manifold, FME, ArcGIS, etc. Use GDAL to interact with OGC API - Coverages Verify you have a recent GDAL installed, else use GDAL from OSGeoLive Run gdalinfo on the command line to verify a connection to OGC API - Coverages: gdalinfo OGCAPI:https://maps.ecere.com/ogcapi/collections/SRTM_ViewFinderPanorama OWSLib OWSlib is a Python library to interact with OGC Web Services and supports a number of OGC APIs including OGC API - Coverages. Interact with OGC API - Coverages via OWSLib If you do not have Python installed, consider running this exercise in a Docker container or in a cloud environment. pip3 install owslib >>> from owslib.ogcapi.coverages import Coverages >>> SERVICE_URL = 'https://demo.pygeoapi.io/master/' >>> w . url 'https://demo.pygeoapi.io/master/' >>> gdps = w . collection ( 'gdps-temperature' ) >>> gdps [ 'id' ] 'gdps-temperature' >>> gdps [ 'title' ] 'Global Deterministic Prediction System sample' >>> gdps [ 'description' ] 'Global Deterministic Prediction System sample' >>> domainset = w . coverage_domainset ( 'gdps-temperature' ) >>> domainset [ 'generalGrid' ][ 'axisLabels' ] [ 'Long' , 'Lat' ] >>> domainset [ 'generalGrid' ][ 'gridLimits' ][ 'axisLabels' ] [ 'i' , 'j' ] >>> rangetype = w . coverage_rangetype ( 'gdps-temperature' ) >>> len ( rangetype [ 'field' ]) 1 >>> rangetype [ 'field' ][ 0 ][ 'name' ] 'Temperature [C]' >>> rangetype [ 'field' ][ 0 ][ 'uom' ][ 'code' ] '[C]' >>> rangetype [ 'field' ][ 0 ][ 'encodingInfo' ][ 'dataType' ] 'http://www.opengis.net/def/dataType/OGC/0/float64' Note See the official OWSLib documentation for more examples. Summary Congratulations! You are now able to publish raster data to pygeoapi.","title":"Exercise 3 - Raster data via OGC API - Coverages"},{"location":"publishing/ogccov/#exercise-3-raster-data-via-ogc-api-coverages","text":"OGC API - Coverages provides a Web API to access raster data (grids, remote sensing data, multidimensional data cubes): OGC API - Coverages ( draft )","title":"Exercise 3 - Raster data via OGC API - Coverages"},{"location":"publishing/ogccov/#pygeoapi-support","text":"pygeoapi supports the OGC API - Coverages draft specification, with rasterio and xarray as core backends and CoverageJSON and native output. Note See the official documentation for more information on supported raster backends","title":"pygeoapi support"},{"location":"publishing/ogccov/#publish-a-raster-dataset","text":"In the previous exercises we have demonstrated the steps involved to publish vector data and update the pygeoapi configuration. In this section we are going to publish a raster file in GeoTIFF format, from a rasterio source provider. Download and unzip the GeoTIFF file: cd workshop/exercises/data curl -O http://dati.cittametropolitana.fi.it/geonetwork/srv/api/records/cmfi:419774cb-e812-4ca4-991d-97f0b747e017/attachments/53.zip unzip 53 .zip You can now add 53_ED1_G.tif to pygeoapi: Update the pygeoapi configuration Open the pygeoapi configuration file in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 firenze-terrains : type : collection title : Administrative boundaries before 2014 description : Cadastral parcels (terrains) from the cadastre. Territory Agency; SIT and Information Networks; keywords : - Cadastral parcels links : - type : text/html rel : canonical title : Administrative boundaries before 2014 href : http://dati.cittametropolitana.fi.it/geonetwork/srv/metadata/cmfi:419774cb-e812-4ca4-991d-97f0b747e017 hreflang : it extents : spatial : bbox : [ 10.70 , 43.43 , 11.76 , 44.25 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers : - type : coverage name : rasterio data : /data/53_ED1_G.tif # place correct path here format : name : GTiff mimetype : application/tiff Tip The rasterio provider format.name directive requires a valid GDAL raster driver short name Save the configuration and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published.","title":"Publish a raster dataset"},{"location":"publishing/ogccov/#client-access","text":"","title":"Client access"},{"location":"publishing/ogccov/#gdalogr","text":"GDAL/OGR provides support for OGC API - Coverages . This means you can use gdalinfo to query and convert data from OGC API - Coverages endpoints just like any other raster data source. This also means you can make connections to OGC API - Coverages endpoints from any software which has an interface to GDAL, such as MapServer, GeoServer, Manifold, FME, ArcGIS, etc. Use GDAL to interact with OGC API - Coverages Verify you have a recent GDAL installed, else use GDAL from OSGeoLive Run gdalinfo on the command line to verify a connection to OGC API - Coverages: gdalinfo OGCAPI:https://maps.ecere.com/ogcapi/collections/SRTM_ViewFinderPanorama","title":"GDAL/OGR"},{"location":"publishing/ogccov/#owslib","text":"OWSlib is a Python library to interact with OGC Web Services and supports a number of OGC APIs including OGC API - Coverages. Interact with OGC API - Coverages via OWSLib If you do not have Python installed, consider running this exercise in a Docker container or in a cloud environment. pip3 install owslib >>> from owslib.ogcapi.coverages import Coverages >>> SERVICE_URL = 'https://demo.pygeoapi.io/master/' >>> w . url 'https://demo.pygeoapi.io/master/' >>> gdps = w . collection ( 'gdps-temperature' ) >>> gdps [ 'id' ] 'gdps-temperature' >>> gdps [ 'title' ] 'Global Deterministic Prediction System sample' >>> gdps [ 'description' ] 'Global Deterministic Prediction System sample' >>> domainset = w . coverage_domainset ( 'gdps-temperature' ) >>> domainset [ 'generalGrid' ][ 'axisLabels' ] [ 'Long' , 'Lat' ] >>> domainset [ 'generalGrid' ][ 'gridLimits' ][ 'axisLabels' ] [ 'i' , 'j' ] >>> rangetype = w . coverage_rangetype ( 'gdps-temperature' ) >>> len ( rangetype [ 'field' ]) 1 >>> rangetype [ 'field' ][ 0 ][ 'name' ] 'Temperature [C]' >>> rangetype [ 'field' ][ 0 ][ 'uom' ][ 'code' ] '[C]' >>> rangetype [ 'field' ][ 0 ][ 'encodingInfo' ][ 'dataType' ] 'http://www.opengis.net/def/dataType/OGC/0/float64' Note See the official OWSLib documentation for more examples.","title":"OWSLib"},{"location":"publishing/ogccov/#summary","text":"Congratulations! You are now able to publish raster data to pygeoapi.","title":"Summary"},{"location":"publishing/ogcedr/","text":"Exercise 6 - Environmental data via OGC - Environmental Data Retrieval OGC API - Environmental Data Retrieval provides a Web API to access environmental data using well defined query patterns: OGC API - Environmental Data Retrieval Standard OGC API - Environmental Data Retrieval uses OGC API - Features as a building block, thus enabling streamlined integration for clients and users. EDR can be considered a convenience API which does not require in depth knowledge about the underlying data store/model. pygeoapi support pygeoapi supports the OGC API - Environmental Data Retrieval specification by leveraging both feature and coverage provider plugins. Note See the official documentation for more information on supported EDR backends Publish environmental data in pygeoapi Let's try publishing some ICOADS data via the EDR xarray plugin. The sample ICOADS data can be found in workshop/exercises/data/coads_sst.nc : Update the pygeoapi configuration Open the pygeoapi configuration file in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 icoads-sst : type : collection title : International Comprehensive Ocean-Atmosphere Data Set (ICOADS) description : International Comprehensive Ocean-Atmosphere Data Set (ICOADS) keywords : - icoads - sst - air temperature extents : spatial : bbox : [ -180 , -90 , 180 , 90 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 temporal : begin : 2000-01-16T06:00:00Z end : 2000-12-16T06:00:00Z links : - type : text/html rel : canonical title : information href : https://psl.noaa.gov/data/gridded/data.coads.1deg.html hreflang : en-US providers : - type : edr name : xarray-edr data : /data/coads_sst.nc format : name : NetCDF mimetype : application/x-netcdf Save the configuration and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published. At first glance, the icoads-sst collection appears as a normal OGC API - Coverages collection. Let's look a bit closer at the colleciton description: Client access Currently there is no support for EDR in common tooling. The example below provides a generic workflow using the Python requests library : >>> import requests >>> collection = requests . get ( 'http://localhost:5000/collections/icoads-sst' ) . json () >>> collection [ 'id' ] 'icoads-sst' >>> collection [ 'title' ] 'International Comprehensive Ocean-Atmosphere Data Set (ICOADS)' >>> collection [ 'description' ] 'International Comprehensive Ocean-Atmosphere Data Set (ICOADS)' >>> collection [ 'parameter-names' ] . keys () dict_keys ([ 'SST' , 'AIRT' , 'UWND' , 'VWND' ]) >>> params = { 'coords' : 'POINT(-28 14)' , 'parameter-name' : 'SST' } >>> position_query = requests . get ( 'http://localhost:5000/collections/icoads-sst/position' , params = params ) . json () >>> position_query [ 'ranges' ][ 'SST' ][ 'values' ] [ 26.755414962768555 , 26.303892135620117 , 26.512916564941406 , 26.799564361572266 , 27.48826026916504 , 28.04759979248047 , 28.745832443237305 , 28.5635986328125 , 28.272104263305664 , 28.526521682739258 , 28.25160026550293 , 27.074399948120117 ] Summary Congratulations! You are now able to publish environmental data to pygeoapi.","title":"Exercise 6 - Environmental data via OGC - Environmental Data Retrieval"},{"location":"publishing/ogcedr/#exercise-6-environmental-data-via-ogc-environmental-data-retrieval","text":"OGC API - Environmental Data Retrieval provides a Web API to access environmental data using well defined query patterns: OGC API - Environmental Data Retrieval Standard OGC API - Environmental Data Retrieval uses OGC API - Features as a building block, thus enabling streamlined integration for clients and users. EDR can be considered a convenience API which does not require in depth knowledge about the underlying data store/model.","title":"Exercise 6 - Environmental data via OGC - Environmental Data Retrieval"},{"location":"publishing/ogcedr/#pygeoapi-support","text":"pygeoapi supports the OGC API - Environmental Data Retrieval specification by leveraging both feature and coverage provider plugins. Note See the official documentation for more information on supported EDR backends","title":"pygeoapi support"},{"location":"publishing/ogcedr/#publish-environmental-data-in-pygeoapi","text":"Let's try publishing some ICOADS data via the EDR xarray plugin. The sample ICOADS data can be found in workshop/exercises/data/coads_sst.nc : Update the pygeoapi configuration Open the pygeoapi configuration file in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 icoads-sst : type : collection title : International Comprehensive Ocean-Atmosphere Data Set (ICOADS) description : International Comprehensive Ocean-Atmosphere Data Set (ICOADS) keywords : - icoads - sst - air temperature extents : spatial : bbox : [ -180 , -90 , 180 , 90 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 temporal : begin : 2000-01-16T06:00:00Z end : 2000-12-16T06:00:00Z links : - type : text/html rel : canonical title : information href : https://psl.noaa.gov/data/gridded/data.coads.1deg.html hreflang : en-US providers : - type : edr name : xarray-edr data : /data/coads_sst.nc format : name : NetCDF mimetype : application/x-netcdf Save the configuration and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published. At first glance, the icoads-sst collection appears as a normal OGC API - Coverages collection. Let's look a bit closer at the colleciton description:","title":"Publish environmental data in pygeoapi"},{"location":"publishing/ogcedr/#client-access","text":"Currently there is no support for EDR in common tooling. The example below provides a generic workflow using the Python requests library : >>> import requests >>> collection = requests . get ( 'http://localhost:5000/collections/icoads-sst' ) . json () >>> collection [ 'id' ] 'icoads-sst' >>> collection [ 'title' ] 'International Comprehensive Ocean-Atmosphere Data Set (ICOADS)' >>> collection [ 'description' ] 'International Comprehensive Ocean-Atmosphere Data Set (ICOADS)' >>> collection [ 'parameter-names' ] . keys () dict_keys ([ 'SST' , 'AIRT' , 'UWND' , 'VWND' ]) >>> params = { 'coords' : 'POINT(-28 14)' , 'parameter-name' : 'SST' } >>> position_query = requests . get ( 'http://localhost:5000/collections/icoads-sst/position' , params = params ) . json () >>> position_query [ 'ranges' ][ 'SST' ][ 'values' ] [ 26.755414962768555 , 26.303892135620117 , 26.512916564941406 , 26.799564361572266 , 27.48826026916504 , 28.04759979248047 , 28.745832443237305 , 28.5635986328125 , 28.272104263305664 , 28.526521682739258 , 28.25160026550293 , 27.074399948120117 ]","title":"Client access"},{"location":"publishing/ogcedr/#summary","text":"Congratulations! You are now able to publish environmental data to pygeoapi.","title":"Summary"},{"location":"publishing/ogcfeat/","text":"Exercise 2 - Vector data via OGC API - Features OGC API - Features provides a Web API to access vector data (geometries and their attributes). While the core specification covers basic data access and query, additional related standards and extensions are in development for the following capabilities: OGC API - Features - Part 1: Core provides basic access and query capabilities OGC API - Features - Part 2: Coordinate Reference Systems by Reference enables the import and export of any data according to dedicated projections OGC API - Features - Part 3: Filtering ( draft ) adds the ability for complex queries using Common Query Language (CQL) OGC API - Features - Part 4: Create, Replace, Update and Delete ( draft ) adds transactional capabilities pygeoapi support pygeoapi supports the core OGC API - Features specification as well as Part 3 for some backends (Elasticsearch). Note See the official documentation for more information on supported vector backends Note See the official documentation for more information on CQL support Publish a vector dataset In the previous section we demonstrated the steps involved to add a dataset to pygeoapi and update the configuration. In this excercise we are going to publish another vector file, this time from a GeoPackage (SQLite3) data source. Tip It may be helpful to open the dataset in QGIS while adding and updating your pygeoapi server to easily evaluate table attributes, names, spatial properties and CRS. Let's add the file workshop/exercises/data/firenze_terrains.gpkg.zip : cd workshop/exercises/data unzip firenze_terrains.gpkg.zip Update the pygeoapi configuration Open the pygeoapi configuration in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 firenze-terrains : type : collection title : Administrative boundaries before 2014 description : Cadastral parcels (terrains) from the cadastre. Territory Agency; SIT and Information Networks; keywords : - Cadastral parcels links : - type : text/html rel : canonical title : Administrative boundaries before 2014 href : http://dati.cittametropolitana.fi.it/geonetwork/srv/metadata/cmfi:c539d359-4387-4f83-a6f4-cd546b3d8443 hreflang : it extents : spatial : bbox : [ 11.23 , 43.75 , 11.28 , 43.78 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers : - type : feature name : SQLiteGPKG data : /data/firenze_terrains.gpkg # place correct path here id_field : fid title_field : codbo table : firenze_terrains Save the file and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published. Note The SQLite driver incidentally has challenges to open the GeoPackage extension on MacOS. Consult the official documentation or try with an alternative data format. pygeoapi as a WFS proxy An interesting use case for pygeoapi is to provide OGC API - Features interface over existing Web Feature Service (WFS) or ESRI FeatureServer endpoints. In this scenario you lower the barrier and increase the usability of existing services to a wider audience. Let's set up an API on top of an existing WFS hosted by the city of Florence. Update the pygeoapi configuration Open the pygeoapi configuration in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 suol_epicentri_storici : type : collection title : Epicenters of the main historical earthquakes description : Location of the epicenters of the main historical earthquakes in the territory of the Metropolitan City of Florence classified by year and intensity keywords : - earthquakes links : - type : text/xml rel : canonical title : Epicenters of the main historical earthquakes href : http://pubblicazioni.cittametropolitana.fi.it/geoserver/territorio/wfs?request=getCapabilities&service=WFS&version=2.0.0 hreflang : it extents : spatial : bbox : [ 10.94 , 43.52 , 11.65 , 44.17 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers : - type : feature name : OGR data : source_type : WFS source : WFS:http://pubblicazioni.cittametropolitana.fi.it/geoserver/territorio/wfs? source_srs : EPSG:3003 target_srs : EPSG:4326 source_capabilities : paging : True source_options : OGR_WFS_LOAD_MULTIPLE_LAYER_DEFN : NO gdal_ogr_options : EMPTY_AS_NULL : NO GDAL_CACHEMAX : 64 CPL_DEBUG : NO id_field : cpti_id title_field : d layer : territorio:suol_epicentri_storici Save the file and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published. Client access QGIS QGIS is one of the first GIS Desktop clients which added support for OGC API - Features. Support has been integrated into the existing WFS provider. Open an OGC API - Features collection in QGIS Follow the steps to add some collections from an OGC API - Features enpoint: Open QGIS (if you don't have QGIS, you can use OSGeoLive) From the Layer menu, select Add Layer > Add WFS layer From the Data source manager panel, choose 'New connection' Add the URL https://demo.pygeoapi.io/master (or the address of a local server) You can now click the detect button and QGIS will notice you are configuring an OGC API - Features endpoint QGIS facilitates to set page size (request is split in multiple requests) for points you can easily set it to 2500 for some polygons with high density, 100 can already be slow Press OK to save the connection and return to the previous screen Now click the Connect button to retireve the collections of the service You can now add collections to your QGIS project You can also build a query to add a subset of the collection Close the Data source manager . Notice that QGIS applied a default styling just like it would if you add a file based layer. You can work with the collection in a similar way; identify, apply styling, filter, export, etc. Tip Install and activate the QGIS Network Logger extension. It will display HTTP traffice within QGIS and is a valuable tool in debugging failing connections. Note An increasing number of GIS Desktop clients add support for OGC API's in subsequent releases. For example ArcGIS Pro supports OGC API - Features since release 2.8. GDAL/OGR GDAL/OGR provides support for OGC API - Features . This means you can use ogrinfo , ogr2ogr to query and convert data from OGC API - Features endpoints just like any other vector data source. This also means you can make connections to OGC API - Features endpoints from any software which has an interface to GDAL, such as MapServer, GeoServer, Manifold, FME, ArcGIS, etc. Use OGR to interact with OGC API - Features Verify you have a recent GDAL installed, else use GDAL from OSGeoLive Run ogrinfo on the command line to verify a connection to OGC API - Features ogrinfo OAPIF:https://demo.pygeoapi.io/master/collections/obs Now, let's convert the observations into a shapefile ogr2ogr -f \"ESRI Shapefile\" obs.shp OAPIF:https://demo.pygeoapi.io/master/collections/obs Note You can even use OGR to append new features to an OGC API - Features collection which supports transactions (pygeoapi transaction support is planned for future implementation) OWSlib OWSlib is a Python library to interact with OGC Web Services and supports a number of OGC APIs including OGC API - Features. Interact with OGC API - Features via OWSLib If you do not have Python installed, consider running this exercise in a Docker container or in a cloud environment. pip3 install owslib Then start a Python console session with: python (stop the session by typing exit() ). >>> from owslib.ogcapi.features import Features >>> w = Features ( 'https://demo.pygeoapi.io/master' ) >>> w . url 'https://demo.pygeoapi.io/master' >>> conformance = w . conformance () { u 'conformsTo' : [ u 'http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core' , u 'http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/oas30' , u 'http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/html' , u 'http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/geojson' ]} >>> api = w . api () # OpenAPI document/ >>> collections = w . collections () >>> len ( collections [ 'collections' ]) 13 >>> feature_collections = w . feature_collections () >>> len ( feature_collections ) 13 >>> lakes = w . collection ( 'lakes' ) >>> lakes [ 'id' ] 'lakes' >>> lakes [ 'title' ] 'Large Lakes' >>> lakes [ 'description' ] 'lakes of the world, public domain' >>> lakes_queryables = w . collection_queryables ( 'lakes' ) >>> len ( lakes_queryables [ 'queryables' ]) 6 >>> lakes_query = w . collection_items ( 'lakes' ) >>> lakes_query [ 'features' ][ 0 ][ 'properties' ] { u 'scalerank' : 0 , u 'name_alt' : None , u 'admin' : None , u 'featureclass' : u 'Lake' , u 'id' : 0 , u 'name' : u 'Lake Baikal' } Note See the official OWSLib documentation for more examples. Summary Congratulations! You are now able to publish vector data to pygeoapi.","title":"Exercise 2 - Vector data via OGC API - Features"},{"location":"publishing/ogcfeat/#exercise-2-vector-data-via-ogc-api-features","text":"OGC API - Features provides a Web API to access vector data (geometries and their attributes). While the core specification covers basic data access and query, additional related standards and extensions are in development for the following capabilities: OGC API - Features - Part 1: Core provides basic access and query capabilities OGC API - Features - Part 2: Coordinate Reference Systems by Reference enables the import and export of any data according to dedicated projections OGC API - Features - Part 3: Filtering ( draft ) adds the ability for complex queries using Common Query Language (CQL) OGC API - Features - Part 4: Create, Replace, Update and Delete ( draft ) adds transactional capabilities","title":"Exercise 2 - Vector data via OGC API - Features"},{"location":"publishing/ogcfeat/#pygeoapi-support","text":"pygeoapi supports the core OGC API - Features specification as well as Part 3 for some backends (Elasticsearch). Note See the official documentation for more information on supported vector backends Note See the official documentation for more information on CQL support","title":"pygeoapi support"},{"location":"publishing/ogcfeat/#publish-a-vector-dataset","text":"In the previous section we demonstrated the steps involved to add a dataset to pygeoapi and update the configuration. In this excercise we are going to publish another vector file, this time from a GeoPackage (SQLite3) data source. Tip It may be helpful to open the dataset in QGIS while adding and updating your pygeoapi server to easily evaluate table attributes, names, spatial properties and CRS. Let's add the file workshop/exercises/data/firenze_terrains.gpkg.zip : cd workshop/exercises/data unzip firenze_terrains.gpkg.zip Update the pygeoapi configuration Open the pygeoapi configuration in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 firenze-terrains : type : collection title : Administrative boundaries before 2014 description : Cadastral parcels (terrains) from the cadastre. Territory Agency; SIT and Information Networks; keywords : - Cadastral parcels links : - type : text/html rel : canonical title : Administrative boundaries before 2014 href : http://dati.cittametropolitana.fi.it/geonetwork/srv/metadata/cmfi:c539d359-4387-4f83-a6f4-cd546b3d8443 hreflang : it extents : spatial : bbox : [ 11.23 , 43.75 , 11.28 , 43.78 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers : - type : feature name : SQLiteGPKG data : /data/firenze_terrains.gpkg # place correct path here id_field : fid title_field : codbo table : firenze_terrains Save the file and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published. Note The SQLite driver incidentally has challenges to open the GeoPackage extension on MacOS. Consult the official documentation or try with an alternative data format.","title":"Publish a vector dataset"},{"location":"publishing/ogcfeat/#pygeoapi-as-a-wfs-proxy","text":"An interesting use case for pygeoapi is to provide OGC API - Features interface over existing Web Feature Service (WFS) or ESRI FeatureServer endpoints. In this scenario you lower the barrier and increase the usability of existing services to a wider audience. Let's set up an API on top of an existing WFS hosted by the city of Florence. Update the pygeoapi configuration Open the pygeoapi configuration in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 suol_epicentri_storici : type : collection title : Epicenters of the main historical earthquakes description : Location of the epicenters of the main historical earthquakes in the territory of the Metropolitan City of Florence classified by year and intensity keywords : - earthquakes links : - type : text/xml rel : canonical title : Epicenters of the main historical earthquakes href : http://pubblicazioni.cittametropolitana.fi.it/geoserver/territorio/wfs?request=getCapabilities&service=WFS&version=2.0.0 hreflang : it extents : spatial : bbox : [ 10.94 , 43.52 , 11.65 , 44.17 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers : - type : feature name : OGR data : source_type : WFS source : WFS:http://pubblicazioni.cittametropolitana.fi.it/geoserver/territorio/wfs? source_srs : EPSG:3003 target_srs : EPSG:4326 source_capabilities : paging : True source_options : OGR_WFS_LOAD_MULTIPLE_LAYER_DEFN : NO gdal_ogr_options : EMPTY_AS_NULL : NO GDAL_CACHEMAX : 64 CPL_DEBUG : NO id_field : cpti_id title_field : d layer : territorio:suol_epicentri_storici Save the file and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published.","title":"pygeoapi as a WFS proxy"},{"location":"publishing/ogcfeat/#client-access","text":"","title":"Client access"},{"location":"publishing/ogcfeat/#qgis","text":"QGIS is one of the first GIS Desktop clients which added support for OGC API - Features. Support has been integrated into the existing WFS provider. Open an OGC API - Features collection in QGIS Follow the steps to add some collections from an OGC API - Features enpoint: Open QGIS (if you don't have QGIS, you can use OSGeoLive) From the Layer menu, select Add Layer > Add WFS layer From the Data source manager panel, choose 'New connection' Add the URL https://demo.pygeoapi.io/master (or the address of a local server) You can now click the detect button and QGIS will notice you are configuring an OGC API - Features endpoint QGIS facilitates to set page size (request is split in multiple requests) for points you can easily set it to 2500 for some polygons with high density, 100 can already be slow Press OK to save the connection and return to the previous screen Now click the Connect button to retireve the collections of the service You can now add collections to your QGIS project You can also build a query to add a subset of the collection Close the Data source manager . Notice that QGIS applied a default styling just like it would if you add a file based layer. You can work with the collection in a similar way; identify, apply styling, filter, export, etc. Tip Install and activate the QGIS Network Logger extension. It will display HTTP traffice within QGIS and is a valuable tool in debugging failing connections. Note An increasing number of GIS Desktop clients add support for OGC API's in subsequent releases. For example ArcGIS Pro supports OGC API - Features since release 2.8.","title":"QGIS"},{"location":"publishing/ogcfeat/#gdalogr","text":"GDAL/OGR provides support for OGC API - Features . This means you can use ogrinfo , ogr2ogr to query and convert data from OGC API - Features endpoints just like any other vector data source. This also means you can make connections to OGC API - Features endpoints from any software which has an interface to GDAL, such as MapServer, GeoServer, Manifold, FME, ArcGIS, etc. Use OGR to interact with OGC API - Features Verify you have a recent GDAL installed, else use GDAL from OSGeoLive Run ogrinfo on the command line to verify a connection to OGC API - Features ogrinfo OAPIF:https://demo.pygeoapi.io/master/collections/obs Now, let's convert the observations into a shapefile ogr2ogr -f \"ESRI Shapefile\" obs.shp OAPIF:https://demo.pygeoapi.io/master/collections/obs Note You can even use OGR to append new features to an OGC API - Features collection which supports transactions (pygeoapi transaction support is planned for future implementation)","title":"GDAL/OGR"},{"location":"publishing/ogcfeat/#owslib","text":"OWSlib is a Python library to interact with OGC Web Services and supports a number of OGC APIs including OGC API - Features. Interact with OGC API - Features via OWSLib If you do not have Python installed, consider running this exercise in a Docker container or in a cloud environment. pip3 install owslib Then start a Python console session with: python (stop the session by typing exit() ). >>> from owslib.ogcapi.features import Features >>> w = Features ( 'https://demo.pygeoapi.io/master' ) >>> w . url 'https://demo.pygeoapi.io/master' >>> conformance = w . conformance () { u 'conformsTo' : [ u 'http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core' , u 'http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/oas30' , u 'http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/html' , u 'http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/geojson' ]} >>> api = w . api () # OpenAPI document/ >>> collections = w . collections () >>> len ( collections [ 'collections' ]) 13 >>> feature_collections = w . feature_collections () >>> len ( feature_collections ) 13 >>> lakes = w . collection ( 'lakes' ) >>> lakes [ 'id' ] 'lakes' >>> lakes [ 'title' ] 'Large Lakes' >>> lakes [ 'description' ] 'lakes of the world, public domain' >>> lakes_queryables = w . collection_queryables ( 'lakes' ) >>> len ( lakes_queryables [ 'queryables' ]) 6 >>> lakes_query = w . collection_items ( 'lakes' ) >>> lakes_query [ 'features' ][ 0 ][ 'properties' ] { u 'scalerank' : 0 , u 'name_alt' : None , u 'admin' : None , u 'featureclass' : u 'Lake' , u 'id' : 0 , u 'name' : u 'Lake Baikal' } Note See the official OWSLib documentation for more examples.","title":"OWSlib"},{"location":"publishing/ogcfeat/#summary","text":"Congratulations! You are now able to publish vector data to pygeoapi.","title":"Summary"},{"location":"publishing/ogcrec/","text":"Exercise 5 - Metadata via OGC API - Records OGC API - Records provides a Web API with the capability to create, modify, and query metadata on the Web: OGC API - Records: Part 1: Core ( draft ) OGC API - Records uses OGC API - Features as a building block, thus enabling streamlined deployment and integration for clients and users. pygeoapi support pygeoapi supports the OGC API - Records draft specification, using Elasticsearch and TinyDB rasterio and xarray as core backends. Note See the official documentation for more information on supported catalogue/metadata backends Publish metadata records in pygeoapi With pygeoapi we can setup OGC API - Records using any supported data provider. In this exercise we will use the TinyDB Catalogue backend. We will use the sample catalogue in workshop/exercises/data/records/catalogue.tinydb . Update the pygeoapi configuration Open the pygeoapi configuration file in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 example_catalogue : type : collection title : FOSS4G Florence Record catalogue description : FOSS4G Florence Record catalogue (OGC API - Records) keywords : - Services - Infrastructures - Florence - FOSS4G links : - type : text/html rel : canonical title : information href : http://opendata.comune.firenze.it hreflang : en-US extents : spatial : bbox : [ 11.145 , 43.718 , 11.348 , 43.84 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers : - type : record name : TinyDBCatalogue data : /data/records/catalogue.tinydb id_field : externalId time_field : recordCreated title_field : title Save the configuration and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published. Metadata formats By default, pygeoapi supports and expects the OGC API - Records core record model and queryables. For additional metadata formats, you can develop your own custom pygeoapi plugin, or convert your metadata to OGC API - Records core record model before adding to pygeoapi. Sample ISO 19139 to TinyDBCatalogue loader It's possible to load more example ISO19139 metadata in a TinyDB database with the following script ( raw ) python3 load_tinydb_records.py /xml_folder/ /db_folder/sample-records.tinydb Client access QGIS QGIS supports OGC API - Records via the MetaSearch plugin . MetaSearch originally focused on Catalogue Service for the Web (OGC:CSW) only, but has been extended to OGC API - Records. MetaSearch is a default plugin in QGIS and requires no further installation. Query OGC API - Records from QGIS Follow these steps to connect to a service and query datasets: Locate the MetaSearch plugin in the Web menu or on the Toolbar . The main search panel will appear with the default MetaSearch catalogue list already populated. open the Services tab, to find the New button to create a new connection add a connection to https://demo.pygeoapi.io/master click Service Info to get information about the service return to the Search tab select the connection you have just created type a search term and click search notice that when you select a search result, a red footprint is drawn on the map highlighting the location of the dataset OWSlib is a Python library to interact with OGC Web Services and supports a number of OGC APIs including OGC API - Records. Interact with OGC API - Records via OWSLib If you do not have Python installed, consider running this exercise in a Docker container or in a cloud environment. pip3 install owslib Then start a Python console session with: python (stop the session by typing exit() ). >>> from owslib.ogcapi.records import Records >>> SERVICE_URL = 'https://demo.pygeoapi.io/master/' >>> w = Records ( SERVICE_URL ) >>> w . url 'https://demo.pygeoapi.io/master' >>> dutch_metacat = w . collection ( 'dutch-metadata' ) >>> dutch_metacat [ 'id' ] 'dutch-metadata' >>> dutch_metacat [ 'title' ] 'Sample metadata records from Dutch Nationaal georegister' >>> dutch_metacat [ 'description' ] 'Sample metadata records from Dutch Nationaal georegister' >>> dutch_metacat_query = w . collection_items ( 'dutch-metadata' , limit = 1 ) >>> dutch_metacat_query [ 'numberMatched' ] 198 >>> dutch_metacat_query [ 'numberReturned' ] 1 >>> dutch_metacat_query = w . collection_items ( 'dutch-metadata' , q = 'Wegpanorama' ) >>> dutch_metacat_query [ 'numberMatched' ] 2 Note See the official OWSLib documentation for more examples. Summary Congratulations! You are now able to publish metadata to pygeoapi.","title":"Exercise 5 - Metadata via OGC API - Records"},{"location":"publishing/ogcrec/#exercise-5-metadata-via-ogc-api-records","text":"OGC API - Records provides a Web API with the capability to create, modify, and query metadata on the Web: OGC API - Records: Part 1: Core ( draft ) OGC API - Records uses OGC API - Features as a building block, thus enabling streamlined deployment and integration for clients and users.","title":"Exercise 5 - Metadata via OGC API - Records"},{"location":"publishing/ogcrec/#pygeoapi-support","text":"pygeoapi supports the OGC API - Records draft specification, using Elasticsearch and TinyDB rasterio and xarray as core backends. Note See the official documentation for more information on supported catalogue/metadata backends","title":"pygeoapi support"},{"location":"publishing/ogcrec/#publish-metadata-records-in-pygeoapi","text":"With pygeoapi we can setup OGC API - Records using any supported data provider. In this exercise we will use the TinyDB Catalogue backend. We will use the sample catalogue in workshop/exercises/data/records/catalogue.tinydb . Update the pygeoapi configuration Open the pygeoapi configuration file in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 example_catalogue : type : collection title : FOSS4G Florence Record catalogue description : FOSS4G Florence Record catalogue (OGC API - Records) keywords : - Services - Infrastructures - Florence - FOSS4G links : - type : text/html rel : canonical title : information href : http://opendata.comune.firenze.it hreflang : en-US extents : spatial : bbox : [ 11.145 , 43.718 , 11.348 , 43.84 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 providers : - type : record name : TinyDBCatalogue data : /data/records/catalogue.tinydb id_field : externalId time_field : recordCreated title_field : title Save the configuration and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published.","title":"Publish metadata records in pygeoapi"},{"location":"publishing/ogcrec/#metadata-formats","text":"By default, pygeoapi supports and expects the OGC API - Records core record model and queryables. For additional metadata formats, you can develop your own custom pygeoapi plugin, or convert your metadata to OGC API - Records core record model before adding to pygeoapi.","title":"Metadata formats"},{"location":"publishing/ogcrec/#sample-iso-19139-to-tinydbcatalogue-loader","text":"It's possible to load more example ISO19139 metadata in a TinyDB database with the following script ( raw ) python3 load_tinydb_records.py /xml_folder/ /db_folder/sample-records.tinydb","title":"Sample ISO 19139 to TinyDBCatalogue loader"},{"location":"publishing/ogcrec/#client-access","text":"","title":"Client access"},{"location":"publishing/ogcrec/#qgis","text":"QGIS supports OGC API - Records via the MetaSearch plugin . MetaSearch originally focused on Catalogue Service for the Web (OGC:CSW) only, but has been extended to OGC API - Records. MetaSearch is a default plugin in QGIS and requires no further installation. Query OGC API - Records from QGIS Follow these steps to connect to a service and query datasets: Locate the MetaSearch plugin in the Web menu or on the Toolbar . The main search panel will appear with the default MetaSearch catalogue list already populated. open the Services tab, to find the New button to create a new connection add a connection to https://demo.pygeoapi.io/master click Service Info to get information about the service return to the Search tab select the connection you have just created type a search term and click search notice that when you select a search result, a red footprint is drawn on the map highlighting the location of the dataset OWSlib is a Python library to interact with OGC Web Services and supports a number of OGC APIs including OGC API - Records. Interact with OGC API - Records via OWSLib If you do not have Python installed, consider running this exercise in a Docker container or in a cloud environment. pip3 install owslib Then start a Python console session with: python (stop the session by typing exit() ). >>> from owslib.ogcapi.records import Records >>> SERVICE_URL = 'https://demo.pygeoapi.io/master/' >>> w = Records ( SERVICE_URL ) >>> w . url 'https://demo.pygeoapi.io/master' >>> dutch_metacat = w . collection ( 'dutch-metadata' ) >>> dutch_metacat [ 'id' ] 'dutch-metadata' >>> dutch_metacat [ 'title' ] 'Sample metadata records from Dutch Nationaal georegister' >>> dutch_metacat [ 'description' ] 'Sample metadata records from Dutch Nationaal georegister' >>> dutch_metacat_query = w . collection_items ( 'dutch-metadata' , limit = 1 ) >>> dutch_metacat_query [ 'numberMatched' ] 198 >>> dutch_metacat_query [ 'numberReturned' ] 1 >>> dutch_metacat_query = w . collection_items ( 'dutch-metadata' , q = 'Wegpanorama' ) >>> dutch_metacat_query [ 'numberMatched' ] 2 Note See the official OWSLib documentation for more examples.","title":"QGIS"},{"location":"publishing/ogcrec/#summary","text":"Congratulations! You are now able to publish metadata to pygeoapi.","title":"Summary"},{"location":"publishing/ogctile/","text":"Exercise 4 - Tiles of geospatial data via OGC API - Tiles OGC API - Tiles provides a Web API to deliver tiled data (bitmaps or vectors), extending the functionalty other OGC API standards: OGC API - Tiles: Part 1: Core ( draft ) Note OGC API - Tiles extends the collections/* URL structure (tilesets are listed under /collections/example/tiles : https://demo.pygeoapi.io/collections/lakes/tiles/WorldCRS84Quad/{tileMatrix}/{tileRow}/{tileCol}?f=mvt pygeoapi support pygeoapi supports the core OGC API - Tiles specification, and is able to advertise an existing tileset. Note that pygeoapi itself does not render tiles from source data (tiles must be pre-rendered before serving). Existing tools to create tiles include, but are not limited to: TileMill MapProxy QGIS tippecanoe : !!! The OGC API - Tiles URL structure is compatible with XYZ layers in common libraries such as OpenLayers, Leaflet and MapML Note See the official documentation for more information on supported tile backends Publish a tile dataset For this exercise, you will publish a vector dataset of cycle paths, from the city of Florence, from the locations below: data: workshop/exercises/data/cycle-lanes-firenze.geojson metadata: workshop/exercises/data/cycle-lanes-firenze.qmd Let's generate the tiles as the first step using tippecanoe: cd workshop/exercises docker run -it --rm -v ${ PWD } /data:/data emotionalcities/tippecanoe \\ tippecanoe --output-to-directory = /data/tiles/ --force --maximum-zoom = 16 --drop-densest-as-needed --extend-zooms-if-still-dropping --no-tile-compression /data/cycle-lanes-firenze.geojson Update the pygeoapi configuration Open the pygeoapi configuration in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 Cycle : type : collection title : Cycle Circulation Area in Florence description : Cycle lanes and other cycle paths in the city of Florence. keywords : - cycle links : - type : text/html rel : canonical title : information href : http://opendata.comune.firenze.it/?q=metarepo/datasetinfo&id=52d8d3ab-eae5-400e-8561-d974f8612de0 hreflang : en-US extents : spatial : bbox : [ -180 , -90 , 180 , 90 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 temporal : begin : 2011-11-11 end : null # or empty providers : - type : feature name : GeoJSON data : /data/cycle-lanes-firenze.geojson #id_field: accicid - type : tile name : MVT data : /data/tiles #data: tests/data/tiles/DATASET options : metadata_format : tilejson # default | tilejson bounds : [[ 11.1861935050234251 , 43.7512761718001855 ],[ 11.3125196304517655 , 43.8129406631082645 ]] zoom : min : 0 max : 16 schemes : - WorldCRS84Quad format : name : pbf mimetype : application/vnd.mapbox-vector-tile Save the file and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published. Additional check for the following tile specific endpoints in the Cycle collection: tile links in http://localhost:5000/collections/Cycle tile metadata in http://localhost:5000/collections/Cycle/tiles/WorldCRS84Quad/metadata Client access QGIS QGIS supports OGC API Vector Tiles via the Vector Tiles Layer . Although OGC API - Tiles are not natively supported, you can customize the generic connection in order to access them in QGIS. Access OGC API Vector Tiles from QGIS Before entering QGIS, access your pygeoapi installation page on the browser and follow these steps. access the collection page of the tiles dataset: http://localhost:5000/collections/Cycle navigate to the tiles page by clicking on tiles : http://localhost:5000/collections/Cycle/tiles click in Tiles metadata in tilejson format : http://localhost:5000/collections/Cycle/tiles/WorldCRS84Quad/metadata note the URL in tiles : http://localhost:5000/collections/Cycle/tiles/WorldCRS84Quad/{tileMatrix}/{tileRow}/{tileCol}?f=mvt and of the values of minZoom and maxZoom Follow these steps to connect to a service and access vector tiles: locate the vector tiles service on the left hand side browser panel. Note that you can also use the top menu and navigate to Layer > Add Layer > Vector Tile Layer right-click to bring up the context menu and choose New Generic connection fill the required values. For URL, use the URL you noted from the previous step, replacing {tileMatrix}/{tileRow}/{tileCol} with {z}/{x}/{y} . press OK to add the service. At this point, if you are using the browser you should see the collection appearing in the menu, below \"Vector Tiles\" double-click in the collection to add it to the map remember to set the CRS of the map to EPSG:4326 by clicking in the button on the lower right corner zoom in to Florence to visualize your dataset LeafletJS LeafletJS is a popular JavaScript library to add interactive maps to websites. LeafletJS does not support OGC API's explicitely, however can interact with OGC API by using the results of the API directly. Add OGC API - Tiles to a website with LeafletJS copy the HTML below to a file called vector-tiles.html , or locate this file in workshop/exercises/html open the file in a web browser The code uses the LeafletJS library with the leaflet.vectorgrid plugin to display the lakes OGC API - Tiles service on top of an OpenStreetMap base layer. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 < html > < head >< title > OGC API - Tiles exercise </ title ></ head > < body > < div id = \"map\" style = \"width:100vw;height:100vh;\" ></ div > < link rel = \"stylesheet\" href = \"https://unpkg.com/leaflet@1.0.3/dist/leaflet.css\" /> < script type = \"text/javascript\" src = \"https://unpkg.com/leaflet@1.3.1/dist/leaflet.js\" ></ script > < script type = \"text/javascript\" src = \"https://unpkg.com/leaflet.vectorgrid@1.2.0\" ></ script > < script > map = L . map ( 'map' ). setView ({ lat : 43.79 , lng : 11.25 }, 12 ); map . addLayer ( new L . tileLayer ( 'https://stamen-tiles-{s}.a.ssl.fastly.net/watercolor/{z}/{x}/{y}.{ext}' , { attribution : 'Map tiles by <a href=\"https://stamen.com\">Stamen Design</a>, <a href=\"https://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a> &mdash; Map data &copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors' , subdomains : 'abcd' , minZoom : 1 , maxZoom : 16 , ext : 'jpg' })); map . addLayer ( new L . vectorGrid . protobuf ( 'http://localhost:5000/collections/Cycle/tiles/WorldCRS84Quad/{z}/{x}/{y}?f=mvt' , { rendererFactory : L . canvas . tile })); </ script > </ body > </ html > Tip Try adding a different pygeoapi vector tiles layer by updating the code in workshop/exercises/html/vector-tiles.html . OpenLayers OpenLayers is a popular JavaScript library to add interactive maps to websites. OpenLayers natively supports OGC API - Tiles. Tip See the official OpenLayers documentation Summary Congratulations! You are now able to publish tiles to pygeoapi.","title":"Exercise 4 - Tiles of geospatial data via OGC API - Tiles"},{"location":"publishing/ogctile/#exercise-4-tiles-of-geospatial-data-via-ogc-api-tiles","text":"OGC API - Tiles provides a Web API to deliver tiled data (bitmaps or vectors), extending the functionalty other OGC API standards: OGC API - Tiles: Part 1: Core ( draft ) Note OGC API - Tiles extends the collections/* URL structure (tilesets are listed under /collections/example/tiles : https://demo.pygeoapi.io/collections/lakes/tiles/WorldCRS84Quad/{tileMatrix}/{tileRow}/{tileCol}?f=mvt","title":"Exercise 4 - Tiles of geospatial data via OGC API - Tiles"},{"location":"publishing/ogctile/#pygeoapi-support","text":"pygeoapi supports the core OGC API - Tiles specification, and is able to advertise an existing tileset. Note that pygeoapi itself does not render tiles from source data (tiles must be pre-rendered before serving). Existing tools to create tiles include, but are not limited to: TileMill MapProxy QGIS tippecanoe : !!! The OGC API - Tiles URL structure is compatible with XYZ layers in common libraries such as OpenLayers, Leaflet and MapML Note See the official documentation for more information on supported tile backends","title":"pygeoapi support"},{"location":"publishing/ogctile/#publish-a-tile-dataset","text":"For this exercise, you will publish a vector dataset of cycle paths, from the city of Florence, from the locations below: data: workshop/exercises/data/cycle-lanes-firenze.geojson metadata: workshop/exercises/data/cycle-lanes-firenze.qmd Let's generate the tiles as the first step using tippecanoe: cd workshop/exercises docker run -it --rm -v ${ PWD } /data:/data emotionalcities/tippecanoe \\ tippecanoe --output-to-directory = /data/tiles/ --force --maximum-zoom = 16 --drop-densest-as-needed --extend-zooms-if-still-dropping --no-tile-compression /data/cycle-lanes-firenze.geojson Update the pygeoapi configuration Open the pygeoapi configuration in a text editor. Add a new dataset section as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 Cycle : type : collection title : Cycle Circulation Area in Florence description : Cycle lanes and other cycle paths in the city of Florence. keywords : - cycle links : - type : text/html rel : canonical title : information href : http://opendata.comune.firenze.it/?q=metarepo/datasetinfo&id=52d8d3ab-eae5-400e-8561-d974f8612de0 hreflang : en-US extents : spatial : bbox : [ -180 , -90 , 180 , 90 ] crs : http://www.opengis.net/def/crs/OGC/1.3/CRS84 temporal : begin : 2011-11-11 end : null # or empty providers : - type : feature name : GeoJSON data : /data/cycle-lanes-firenze.geojson #id_field: accicid - type : tile name : MVT data : /data/tiles #data: tests/data/tiles/DATASET options : metadata_format : tilejson # default | tilejson bounds : [[ 11.1861935050234251 , 43.7512761718001855 ],[ 11.3125196304517655 , 43.8129406631082645 ]] zoom : min : 0 max : 16 schemes : - WorldCRS84Quad format : name : pbf mimetype : application/vnd.mapbox-vector-tile Save the file and restart docker compose. Navigate to http://localhost:5000/collections to evaluate whether the new dataset has been published. Additional check for the following tile specific endpoints in the Cycle collection: tile links in http://localhost:5000/collections/Cycle tile metadata in http://localhost:5000/collections/Cycle/tiles/WorldCRS84Quad/metadata","title":"Publish a tile dataset"},{"location":"publishing/ogctile/#client-access","text":"","title":"Client access"},{"location":"publishing/ogctile/#qgis","text":"QGIS supports OGC API Vector Tiles via the Vector Tiles Layer . Although OGC API - Tiles are not natively supported, you can customize the generic connection in order to access them in QGIS. Access OGC API Vector Tiles from QGIS Before entering QGIS, access your pygeoapi installation page on the browser and follow these steps. access the collection page of the tiles dataset: http://localhost:5000/collections/Cycle navigate to the tiles page by clicking on tiles : http://localhost:5000/collections/Cycle/tiles click in Tiles metadata in tilejson format : http://localhost:5000/collections/Cycle/tiles/WorldCRS84Quad/metadata note the URL in tiles : http://localhost:5000/collections/Cycle/tiles/WorldCRS84Quad/{tileMatrix}/{tileRow}/{tileCol}?f=mvt and of the values of minZoom and maxZoom Follow these steps to connect to a service and access vector tiles: locate the vector tiles service on the left hand side browser panel. Note that you can also use the top menu and navigate to Layer > Add Layer > Vector Tile Layer right-click to bring up the context menu and choose New Generic connection fill the required values. For URL, use the URL you noted from the previous step, replacing {tileMatrix}/{tileRow}/{tileCol} with {z}/{x}/{y} . press OK to add the service. At this point, if you are using the browser you should see the collection appearing in the menu, below \"Vector Tiles\" double-click in the collection to add it to the map remember to set the CRS of the map to EPSG:4326 by clicking in the button on the lower right corner zoom in to Florence to visualize your dataset","title":"QGIS"},{"location":"publishing/ogctile/#leafletjs","text":"LeafletJS is a popular JavaScript library to add interactive maps to websites. LeafletJS does not support OGC API's explicitely, however can interact with OGC API by using the results of the API directly. Add OGC API - Tiles to a website with LeafletJS copy the HTML below to a file called vector-tiles.html , or locate this file in workshop/exercises/html open the file in a web browser The code uses the LeafletJS library with the leaflet.vectorgrid plugin to display the lakes OGC API - Tiles service on top of an OpenStreetMap base layer. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 < html > < head >< title > OGC API - Tiles exercise </ title ></ head > < body > < div id = \"map\" style = \"width:100vw;height:100vh;\" ></ div > < link rel = \"stylesheet\" href = \"https://unpkg.com/leaflet@1.0.3/dist/leaflet.css\" /> < script type = \"text/javascript\" src = \"https://unpkg.com/leaflet@1.3.1/dist/leaflet.js\" ></ script > < script type = \"text/javascript\" src = \"https://unpkg.com/leaflet.vectorgrid@1.2.0\" ></ script > < script > map = L . map ( 'map' ). setView ({ lat : 43.79 , lng : 11.25 }, 12 ); map . addLayer ( new L . tileLayer ( 'https://stamen-tiles-{s}.a.ssl.fastly.net/watercolor/{z}/{x}/{y}.{ext}' , { attribution : 'Map tiles by <a href=\"https://stamen.com\">Stamen Design</a>, <a href=\"https://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a> &mdash; Map data &copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors' , subdomains : 'abcd' , minZoom : 1 , maxZoom : 16 , ext : 'jpg' })); map . addLayer ( new L . vectorGrid . protobuf ( 'http://localhost:5000/collections/Cycle/tiles/WorldCRS84Quad/{z}/{x}/{y}?f=mvt' , { rendererFactory : L . canvas . tile })); </ script > </ body > </ html > Tip Try adding a different pygeoapi vector tiles layer by updating the code in workshop/exercises/html/vector-tiles.html .","title":"LeafletJS"},{"location":"publishing/ogctile/#openlayers","text":"OpenLayers is a popular JavaScript library to add interactive maps to websites. OpenLayers natively supports OGC API - Tiles. Tip See the official OpenLayers documentation","title":"OpenLayers"},{"location":"publishing/ogctile/#summary","text":"Congratulations! You are now able to publish tiles to pygeoapi.","title":"Summary"}]}